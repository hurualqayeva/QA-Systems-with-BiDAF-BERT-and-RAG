{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-06T18:58:49.975117Z",
     "start_time": "2025-05-06T18:58:38.917546Z"
    }
   },
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "squad: DatasetDict = load_dataset(\"squad\")\n",
    "squad_train: Dataset = squad['train']\n",
    "squad_validation: Dataset = squad['validation']"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T19:33:17.250327Z",
     "start_time": "2025-05-06T19:33:16.827760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"tagger\", \"ner\", \"lemmatizer\", \"attribute_ruler\"])\n",
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "id": "965b94f7b22ba4af",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T21:00:17.748061Z",
     "start_time": "2025-05-06T21:00:17.542817Z"
    }
   },
   "cell_type": "code",
   "source": "len(squad_train['context'][0])",
   "id": "72d66ff42a24a267",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T21:07:04.196867Z",
     "start_time": "2025-05-06T21:07:04.022105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_lengths = [len(context) for context in squad_train['context']]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.quantile(context_lengths, [0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ],
   "id": "53a945fb2bcfddc1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 559. ,  693. ,  895. , 1147. , 1328.1, 1749. ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T19:44:22.477206Z",
     "start_time": "2025-05-06T19:33:18.058573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_example_spacy(example):\n",
    "    # Tokenize context\n",
    "    context_doc = nlp(example['context'])\n",
    "    tokenized_context = [token.text for token in context_doc]\n",
    "    context_token_char_offsets = [token.idx for token in context_doc]\n",
    "\n",
    "    # Tokenize question\n",
    "    question_doc = nlp(example['question'])\n",
    "    tokenized_question = [token.text for token in question_doc]\n",
    "\n",
    "    # --- Crucial Step: Map Answer Spans (Simplified) ---\n",
    "    # Since there's always one answer for your dataset version:\n",
    "    answer_char_start = example['answers']['answer_start'][0]\n",
    "    answer_text = example['answers']['text'][0]\n",
    "    answer_char_end = answer_char_start + len(answer_text)\n",
    "\n",
    "    token_answer_start_idx = -1\n",
    "    token_answer_end_idx = -1\n",
    "\n",
    "    # Find token start index\n",
    "    # Iterate through tokens and their character offsets\n",
    "    for i, token in enumerate(context_doc):\n",
    "        # Check if the answer's character start falls within the current token's span\n",
    "        if token.idx <= answer_char_start < token.idx + len(token.text):\n",
    "            token_answer_start_idx = i\n",
    "            break\n",
    "    # If not found by the above (e.g., answer starts exactly at a token boundary after whitespace)\n",
    "    # try finding the first token whose start offset is >= answer_char_start\n",
    "    if token_answer_start_idx == -1:\n",
    "        for i, token in enumerate(context_doc):\n",
    "            if token.idx >= answer_char_start:\n",
    "                # Check if this token or the previous one is a better fit\n",
    "                # This might need more refinement if answers can be leading/trailing spaces of tokens\n",
    "                if i > 0 and (context_doc[i-1].idx + len(context_doc[i-1].text) > answer_char_start):\n",
    "                     # This condition suggests the previous token might be part of the start\n",
    "                     # This area can be complex if tokenization and answer boundaries are tricky\n",
    "                     # For now, we'll stick to simpler logic often sufficient for SQuAD\n",
    "                     pass # For now, we assume the first token whose .idx >= answer_char_start is fine if the previous check failed.\n",
    "                token_answer_start_idx = i\n",
    "                break\n",
    "\n",
    "\n",
    "    # Find token end index\n",
    "    if token_answer_start_idx != -1:\n",
    "        for i in range(token_answer_start_idx, len(context_doc)):\n",
    "            token = context_doc[i]\n",
    "            # The end token is the last token whose text is part of the answer.\n",
    "            # So, if this token's end character position is >= the answer's character end, it's a candidate.\n",
    "            if (token.idx + len(token.text)) >= answer_char_end:\n",
    "                token_answer_end_idx = i\n",
    "                break\n",
    "        # Sanity check: if token_answer_end_idx is found, ensure the span isn't empty\n",
    "        # and that the reconstructed text roughly matches. This is more for debugging.\n",
    "        # if token_answer_start_idx != -1 and token_answer_end_idx != -1 :\n",
    "        #     reconstructed_answer = \"\".join(t.text_with_ws for t in context_doc[token_answer_start_idx:token_answer_end_idx+1]).strip()\n",
    "        #     if not answer_text in reconstructed_answer : # Be careful with exact match due to tokenization nuances\n",
    "        #         print(f\"Warning: Mismatch for example ID {example['id']}. Original: '{answer_text}', Reconstructed: '{reconstructed_answer}' from tokens {token_answer_start_idx}-{token_answer_end_idx}\")\n",
    "\n",
    "\n",
    "    # Fallback or error handling if spans are not found properly\n",
    "    if token_answer_start_idx == -1 or token_answer_end_idx == -1:\n",
    "        # This indicates an issue with answer span mapping.\n",
    "        # For SQuAD v1.1, an answer is guaranteed.\n",
    "        # You might need to refine the logic or flag these examples.\n",
    "        print(f\"Warning: Could not map answer for example ID {example['id']}. Context: '{example['context']}', Answer: '{answer_text}' at char {answer_char_start}. Tok_start: {token_answer_start_idx}, Tok_end: {token_answer_end_idx}\")\n",
    "        # For BiDAF, you need valid start/end token indices.\n",
    "        # Assigning -1 or skipping might be options, but ideally, all SQuAD v1.1 answers should be mappable.\n",
    "\n",
    "    return {\n",
    "        \"tokenized_context\": tokenized_context,\n",
    "        \"tokenized_question\": tokenized_question,\n",
    "        \"context_token_char_offsets\": context_token_char_offsets, # Good for debugging\n",
    "        \"token_answer_start\": token_answer_start_idx,\n",
    "        \"token_answer_end\": token_answer_end_idx,\n",
    "        \"id\": example['id'] # Keep id for debugging\n",
    "    }\n",
    "\n",
    "# Then process the whole dataset:\n",
    "print(\"\\nMapping the tokenization function to the training dataset...\")\n",
    "squad_train_tokenized = squad_train.map(tokenize_example_spacy, batched=False)\n",
    "print(\"Mapping the tokenization function to the validation dataset...\")\n",
    "squad_validation_tokenized = squad_validation.map(tokenize_example_spacy, batched=False)\n",
    "\n",
    "# Verify the new columns and an example\n",
    "print(\"\\nFeatures of tokenized training data:\", squad_train_tokenized.features)\n",
    "print(\"\\nFirst example of tokenized training data:\")\n",
    "print(squad_train_tokenized[0])"
   ],
   "id": "b1e5a6fe35207ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mapping the tokenization function to the training dataset...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1ea69ce9d2c44499a505c1bdad91a21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the tokenization function to the validation dataset...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfbf6571a9b34b04b826528c52c5e4e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features of tokenized training data: {'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None), 'tokenized_context': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'tokenized_question': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'context_token_char_offsets': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'token_answer_start': Value(dtype='int64', id=None), 'token_answer_end': Value(dtype='int64', id=None)}\n",
      "\n",
      "First example of tokenized training data:\n",
      "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}, 'tokenized_context': ['Architecturally', ',', 'the', 'school', 'has', 'a', 'Catholic', 'character', '.', 'Atop', 'the', 'Main', 'Building', \"'s\", 'gold', 'dome', 'is', 'a', 'golden', 'statue', 'of', 'the', 'Virgin', 'Mary', '.', 'Immediately', 'in', 'front', 'of', 'the', 'Main', 'Building', 'and', 'facing', 'it', ',', 'is', 'a', 'copper', 'statue', 'of', 'Christ', 'with', 'arms', 'upraised', 'with', 'the', 'legend', '\"', 'Venite', 'Ad', 'Me', 'Omnes', '\"', '.', 'Next', 'to', 'the', 'Main', 'Building', 'is', 'the', 'Basilica', 'of', 'the', 'Sacred', 'Heart', '.', 'Immediately', 'behind', 'the', 'basilica', 'is', 'the', 'Grotto', ',', 'a', 'Marian', 'place', 'of', 'prayer', 'and', 'reflection', '.', 'It', 'is', 'a', 'replica', 'of', 'the', 'grotto', 'at', 'Lourdes', ',', 'France', 'where', 'the', 'Virgin', 'Mary', 'reputedly', 'appeared', 'to', 'Saint', 'Bernadette', 'Soubirous', 'in', '1858', '.', 'At', 'the', 'end', 'of', 'the', 'main', 'drive', '(', 'and', 'in', 'a', 'direct', 'line', 'that', 'connects', 'through', '3', 'statues', 'and', 'the', 'Gold', 'Dome', ')', ',', 'is', 'a', 'simple', ',', 'modern', 'stone', 'statue', 'of', 'Mary', '.'], 'tokenized_question': ['To', 'whom', 'did', 'the', 'Virgin', 'Mary', 'allegedly', 'appear', 'in', '1858', 'in', 'Lourdes', 'France', '?'], 'context_token_char_offsets': [0, 15, 17, 21, 28, 32, 34, 43, 52, 54, 59, 63, 68, 76, 79, 84, 89, 92, 94, 101, 108, 111, 115, 122, 126, 128, 140, 143, 149, 152, 156, 161, 170, 174, 181, 183, 185, 188, 190, 197, 204, 207, 214, 219, 224, 233, 238, 242, 249, 250, 257, 260, 263, 268, 269, 271, 276, 279, 283, 288, 297, 300, 304, 313, 316, 320, 327, 332, 334, 346, 353, 357, 366, 369, 373, 379, 381, 383, 390, 396, 399, 406, 410, 420, 422, 425, 428, 430, 438, 441, 445, 452, 455, 462, 464, 471, 477, 481, 488, 493, 503, 512, 515, 521, 532, 542, 545, 549, 551, 554, 558, 562, 565, 569, 574, 580, 581, 585, 588, 590, 597, 602, 607, 616, 624, 626, 634, 638, 642, 647, 651, 652, 654, 657, 659, 665, 667, 674, 680, 687, 690, 694], 'token_answer_start': 102, 'token_answer_end': 104}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T21:07:59.749629Z",
     "start_time": "2025-05-06T21:07:59.743476Z"
    }
   },
   "cell_type": "code",
   "source": "squad_train_tokenized.features",
   "id": "2a5dfbf39971402a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'title': Value(dtype='string', id=None),\n",
       " 'context': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None),\n",
       " 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None),\n",
       " 'tokenized_context': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'tokenized_question': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'context_token_char_offsets': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'token_answer_start': Value(dtype='int64', id=None),\n",
       " 'token_answer_end': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T21:08:42.035567Z",
     "start_time": "2025-05-06T21:08:28.108690Z"
    }
   },
   "cell_type": "code",
   "source": "squad_train_tokenized['tokenized_context'][0]",
   "id": "927566a37610cd72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Architecturally',\n",
       " ',',\n",
       " 'the',\n",
       " 'school',\n",
       " 'has',\n",
       " 'a',\n",
       " 'Catholic',\n",
       " 'character',\n",
       " '.',\n",
       " 'Atop',\n",
       " 'the',\n",
       " 'Main',\n",
       " 'Building',\n",
       " \"'s\",\n",
       " 'gold',\n",
       " 'dome',\n",
       " 'is',\n",
       " 'a',\n",
       " 'golden',\n",
       " 'statue',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Virgin',\n",
       " 'Mary',\n",
       " '.',\n",
       " 'Immediately',\n",
       " 'in',\n",
       " 'front',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Main',\n",
       " 'Building',\n",
       " 'and',\n",
       " 'facing',\n",
       " 'it',\n",
       " ',',\n",
       " 'is',\n",
       " 'a',\n",
       " 'copper',\n",
       " 'statue',\n",
       " 'of',\n",
       " 'Christ',\n",
       " 'with',\n",
       " 'arms',\n",
       " 'upraised',\n",
       " 'with',\n",
       " 'the',\n",
       " 'legend',\n",
       " '\"',\n",
       " 'Venite',\n",
       " 'Ad',\n",
       " 'Me',\n",
       " 'Omnes',\n",
       " '\"',\n",
       " '.',\n",
       " 'Next',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Main',\n",
       " 'Building',\n",
       " 'is',\n",
       " 'the',\n",
       " 'Basilica',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Sacred',\n",
       " 'Heart',\n",
       " '.',\n",
       " 'Immediately',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'basilica',\n",
       " 'is',\n",
       " 'the',\n",
       " 'Grotto',\n",
       " ',',\n",
       " 'a',\n",
       " 'Marian',\n",
       " 'place',\n",
       " 'of',\n",
       " 'prayer',\n",
       " 'and',\n",
       " 'reflection',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'a',\n",
       " 'replica',\n",
       " 'of',\n",
       " 'the',\n",
       " 'grotto',\n",
       " 'at',\n",
       " 'Lourdes',\n",
       " ',',\n",
       " 'France',\n",
       " 'where',\n",
       " 'the',\n",
       " 'Virgin',\n",
       " 'Mary',\n",
       " 'reputedly',\n",
       " 'appeared',\n",
       " 'to',\n",
       " 'Saint',\n",
       " 'Bernadette',\n",
       " 'Soubirous',\n",
       " 'in',\n",
       " '1858',\n",
       " '.',\n",
       " 'At',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'the',\n",
       " 'main',\n",
       " 'drive',\n",
       " '(',\n",
       " 'and',\n",
       " 'in',\n",
       " 'a',\n",
       " 'direct',\n",
       " 'line',\n",
       " 'that',\n",
       " 'connects',\n",
       " 'through',\n",
       " '3',\n",
       " 'statues',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Gold',\n",
       " 'Dome',\n",
       " ')',\n",
       " ',',\n",
       " 'is',\n",
       " 'a',\n",
       " 'simple',\n",
       " ',',\n",
       " 'modern',\n",
       " 'stone',\n",
       " 'statue',\n",
       " 'of',\n",
       " 'Mary',\n",
       " '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T21:12:06.267575Z",
     "start_time": "2025-05-06T21:11:50.544229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t = [\n",
    "    np.max([len(x) for x in ctx]) for ctx in squad_train_tokenized['tokenized_context']\n",
    "]\n",
    "np.quantile(t, [0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ],
   "id": "e69ea350ddd15925",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12., 13., 14., 15., 16., 20.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T21:12:32.773051Z",
     "start_time": "2025-05-06T21:12:32.758204Z"
    }
   },
   "cell_type": "code",
   "source": "t = np.array(t)",
   "id": "413bbc79b7c449b5",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T21:17:04.922929Z",
     "start_time": "2025-05-06T21:17:04.918784Z"
    }
   },
   "cell_type": "code",
   "source": "np.argmax(t)",
   "id": "68231528498a36c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(72926)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T21:21:17.351209Z",
     "start_time": "2025-05-06T21:21:03.200833Z"
    }
   },
   "cell_type": "code",
   "source": "squad_train_tokenized['tokenized_context'][np.argmax(t == 28)]",
   "id": "4ef74f2b9c840e74",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GE',\n",
       " \"'s\",\n",
       " 'history',\n",
       " 'of',\n",
       " 'working',\n",
       " 'with',\n",
       " 'turbines',\n",
       " 'in',\n",
       " 'the',\n",
       " 'power',\n",
       " '-',\n",
       " 'generation',\n",
       " 'field',\n",
       " 'gave',\n",
       " 'them',\n",
       " 'the',\n",
       " 'engineering',\n",
       " 'know',\n",
       " '-',\n",
       " 'how',\n",
       " 'to',\n",
       " 'move',\n",
       " 'into',\n",
       " 'the',\n",
       " 'new',\n",
       " 'field',\n",
       " 'of',\n",
       " 'aircraft',\n",
       " 'turbosuperchargers.[citation',\n",
       " 'needed',\n",
       " ']',\n",
       " 'Led',\n",
       " 'by',\n",
       " 'Sanford',\n",
       " 'Alexander',\n",
       " 'Moss',\n",
       " ',',\n",
       " 'GE',\n",
       " 'introduced',\n",
       " 'the',\n",
       " 'first',\n",
       " 'superchargers',\n",
       " 'during',\n",
       " 'World',\n",
       " 'War',\n",
       " 'I',\n",
       " ',',\n",
       " 'and',\n",
       " 'continued',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'them',\n",
       " 'during',\n",
       " 'the',\n",
       " 'Interwar',\n",
       " 'period',\n",
       " '.',\n",
       " 'Superchargers',\n",
       " 'became',\n",
       " 'indispensable',\n",
       " 'in',\n",
       " 'the',\n",
       " 'years',\n",
       " 'immediately',\n",
       " 'prior',\n",
       " 'to',\n",
       " 'World',\n",
       " 'War',\n",
       " 'II',\n",
       " ',',\n",
       " 'and',\n",
       " 'GE',\n",
       " 'was',\n",
       " 'the',\n",
       " 'world',\n",
       " 'leader',\n",
       " 'in',\n",
       " 'exhaust',\n",
       " '-',\n",
       " 'driven',\n",
       " 'supercharging',\n",
       " 'when',\n",
       " 'the',\n",
       " 'war',\n",
       " 'started',\n",
       " '.',\n",
       " 'This',\n",
       " 'experience',\n",
       " ',',\n",
       " 'in',\n",
       " 'turn',\n",
       " ',',\n",
       " 'made',\n",
       " 'GE',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'selection',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'the',\n",
       " 'Whittle',\n",
       " 'W.1',\n",
       " 'jet',\n",
       " 'engine',\n",
       " 'that',\n",
       " 'was',\n",
       " 'demonstrated',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'in',\n",
       " '1941',\n",
       " '.',\n",
       " 'GE',\n",
       " 'ranked',\n",
       " 'ninth',\n",
       " 'among',\n",
       " 'United',\n",
       " 'States',\n",
       " 'corporations',\n",
       " 'in',\n",
       " 'the',\n",
       " 'value',\n",
       " 'of',\n",
       " 'wartime',\n",
       " 'production',\n",
       " 'contracts',\n",
       " '.',\n",
       " 'Although',\n",
       " 'their',\n",
       " 'early',\n",
       " 'work',\n",
       " 'with',\n",
       " 'Whittle',\n",
       " \"'s\",\n",
       " 'designs',\n",
       " 'was',\n",
       " 'later',\n",
       " 'handed',\n",
       " 'to',\n",
       " 'Allison',\n",
       " 'Engine',\n",
       " 'Company',\n",
       " ',',\n",
       " 'GE',\n",
       " 'Aviation',\n",
       " 'emerged',\n",
       " 'as',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'largest',\n",
       " 'engine',\n",
       " 'manufacturers',\n",
       " ',',\n",
       " 'second',\n",
       " 'only',\n",
       " 'to',\n",
       " 'the',\n",
       " 'British',\n",
       " 'company',\n",
       " ',',\n",
       " 'Rolls',\n",
       " '-',\n",
       " 'Royce',\n",
       " 'plc',\n",
       " '.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T21:19:52.488870Z",
     "start_time": "2025-05-06T21:19:52.484572Z"
    }
   },
   "cell_type": "code",
   "source": "np.sum(t == 28)",
   "id": "ebaa325a0181b2a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(15)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T19:44:22.808634Z",
     "start_time": "2025-05-06T19:44:22.497102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os # For checking if files exist\n",
    "\n",
    "# --- Configuration for saving/loading ---\n",
    "# Define paths where you want to save your tokenized datasets\n",
    "tokenized_train_path = \"./squad_train_tokenized_spacy\"\n",
    "tokenized_validation_path = \"./squad_validation_tokenized_spacy\"\n",
    "\n",
    "# Save the tokenized datasets\n",
    "print(\"\\nSaving tokenized training data to disk...\")\n",
    "squad_train_tokenized.save_to_disk(tokenized_train_path)\n",
    "print(f\"Saved tokenized training data to {tokenized_train_path}\")\n",
    "\n",
    "print(\"\\nSaving tokenized validation data to disk...\")\n",
    "squad_validation_tokenized.save_to_disk(tokenized_validation_path)\n",
    "print(f\"Saved tokenized validation data to {tokenized_validation_path}\")\n",
    "print(\"Successfully tokenized and saved data.\")"
   ],
   "id": "e03258d8053c453b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving tokenized training data to disk...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8542503ca5a145f7a26def63c1cb38c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tokenized training data to ./squad_train_tokenized_spacy\n",
      "\n",
      "Saving tokenized validation data to disk...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13756e197c0841b198c9a6de187068ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tokenized validation data to ./squad_validation_tokenized_spacy\n",
      "Successfully tokenized and saved data.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T19:49:45.132230Z",
     "start_time": "2025-05-06T19:49:13.564437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Assuming squad_train_tokenized is loaded and available\n",
    "# squad_train_tokenized = Dataset.load_from_disk(\"./squad_train_tokenized_spacy\")\n",
    "# squad_validation_tokenized = Dataset.load_from_disk(\"./squad_validation_tokenized_spacy\")\n",
    "\n",
    "\n",
    "# --- Configuration for Vocabulary ---\n",
    "MIN_WORD_FREQ = 1  # Minimum frequency for a word to be included in the vocabulary\n",
    "VOCAB_SIZE_LIMIT = None # Set to an integer if you want to cap vocab size, e.g., 50000\n",
    "\n",
    "# Special tokens\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "# You can add more special tokens if needed, e.g., SOS_TOKEN, EOS_TOKEN\n",
    "\n",
    "special_tokens = [PAD_TOKEN, UNK_TOKEN]\n",
    "\n",
    "# --- 1. Count word frequencies from the training data ---\n",
    "print(\"Building vocabulary...\")\n",
    "word_counter = Counter()\n",
    "\n",
    "# Iterate through tokenized contexts and questions in the training set\n",
    "for example in squad_train_tokenized:\n",
    "    word_counter.update(example['tokenized_context'])\n",
    "    word_counter.update(example['tokenized_question'])\n",
    "\n",
    "print(f\"Found {len(word_counter)} unique words in the training data.\")\n",
    "\n",
    "# --- 2. Create word_to_idx and idx_to_word mappings ---\n",
    "# Start with special tokens\n",
    "word_to_idx = {token: idx for idx, token in enumerate(special_tokens)}\n",
    "idx_to_word = {idx: token for token, idx in word_to_idx.items()}\n",
    "\n",
    "# Add words from the counter that meet the minimum frequency\n",
    "# Sort words by frequency (most common first) for potential vocab size limiting\n",
    "sorted_words = word_counter.most_common()\n",
    "\n",
    "for word, count in sorted_words:\n",
    "    if count >= MIN_WORD_FREQ:\n",
    "        if word not in word_to_idx: # Ensure not to overwrite special tokens if they appeared in data\n",
    "            idx = len(word_to_idx)\n",
    "            word_to_idx[word] = idx\n",
    "            idx_to_word[idx] = word\n",
    "    if VOCAB_SIZE_LIMIT and len(word_to_idx) >= VOCAB_SIZE_LIMIT:\n",
    "        print(f\"Reached vocabulary size limit of {VOCAB_SIZE_LIMIT}.\")\n",
    "        break\n",
    "\n",
    "print(f\"Vocabulary size (including special tokens): {len(word_to_idx)}\")\n",
    "print(f\"First 10 words in vocab: { {k: word_to_idx[k] for k in list(word_to_idx)[:10]} }\")\n",
    "print(f\"Example: ID for '{UNK_TOKEN}' is {word_to_idx[UNK_TOKEN]}\")\n",
    "if 'the' in word_to_idx: # Check a common word\n",
    "    print(f\"Example: ID for 'the' is {word_to_idx['the']}\")\n",
    "\n",
    "\n",
    "# --- (Optional) Save the vocabulary ---\n",
    "# You might want to save your word_to_idx and idx_to_word\n",
    "# For example, using pickle or json\n",
    "import json\n",
    "\n",
    "vocab_path = \"./squad_vocab_spacy.json\"\n",
    "print(f\"Saving vocabulary to {vocab_path}...\")\n",
    "with open(vocab_path, 'w') as f:\n",
    "    json.dump({'word_to_idx': word_to_idx, 'idx_to_word': idx_to_word}, f)\n",
    "print(\"Vocabulary saved.\")\n",
    "\n",
    "# To load it back later:\n",
    "# with open(vocab_path, 'r') as f:\n",
    "#     vocab_data = json.load(f)\n",
    "#     word_to_idx = vocab_data['word_to_idx']\n",
    "#     idx_to_word = vocab_data['idx_to_word']\n",
    "# print(\"Vocabulary loaded.\")"
   ],
   "id": "9c63ec99d6ce2bf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary...\n",
      "Found 103961 unique words in the training data.\n",
      "Vocabulary size (including special tokens): 103963\n",
      "First 10 words in vocab: {'<PAD>': 0, '<UNK>': 1, 'the': 2, ',': 3, 'of': 4, '.': 5, 'and': 6, 'in': 7, 'to': 8, 'a': 9}\n",
      "Example: ID for '<UNK>' is 1\n",
      "Example: ID for 'the' is 2\n",
      "Saving vocabulary to ./squad_vocab_spacy.json...\n",
      "Vocabulary saved.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:44:52.627132Z",
     "start_time": "2025-05-06T20:42:22.825516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch # We'll need this for the final embedding matrix\n",
    "import json # For loading the vocabulary if you saved it\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to your downloaded GloVe file (e.g., glove.6B.100d.txt)\n",
    "GLOVE_FILE_PATH = \"./glove.840B.300d.txt\" #  <-- Make sure this path is correct!\n",
    "EMBEDDING_DIM = 300 #  <-- This must match the GloVe file you are using (e.g., 100d, 300d)\n",
    "VOCAB_PATH = \"./squad_vocab_spacy.json\" # Path where you saved your vocabulary\n",
    "\n",
    "# Special tokens\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "# --- 1. Load your vocabulary ---\n",
    "print(f\"Loading vocabulary from {VOCAB_PATH}...\")\n",
    "try:\n",
    "    with open(VOCAB_PATH, 'r') as f:\n",
    "        vocab_data = json.load(f)\n",
    "        word_to_idx = vocab_data['word_to_idx']\n",
    "        idx_to_word = vocab_data['idx_to_word'] # Not strictly needed here, but good to have\n",
    "    print(\"Vocabulary loaded successfully.\")\n",
    "    VOCAB_SIZE = len(word_to_idx)\n",
    "    print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Vocabulary file not found at {VOCAB_PATH}. Please ensure you've built and saved the vocabulary first.\")\n",
    "    exit() # Or handle this error appropriately\n",
    "\n",
    "# --- 2. Load GloVe vectors from file ---\n",
    "print(f\"Loading GloVe vectors from {GLOVE_FILE_PATH}...\")\n",
    "glove_vectors = {}\n",
    "try:\n",
    "    with open(GLOVE_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            try:\n",
    "                vector = np.asarray(parts[1:], dtype='float32')\n",
    "            except ValueError as e:\n",
    "                continue # Skip lines with malformed vectors\n",
    "            glove_vectors[word] = vector\n",
    "    print(f\"Loaded {len(glove_vectors)} word vectors from GloVe.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: GloVe file not found at {GLOVE_FILE_PATH}. Please download it and check the path.\")\n",
    "    exit() # Or handle appropriately\n",
    "\n",
    "# --- 3. Create the embedding matrix ---\n",
    "print(\"Creating embedding matrix...\")\n",
    "# Initialize with random values (e.g., from a normal distribution) or zeros\n",
    "# Small random values are often better than zeros for non-PAD, non-GloVe words.\n",
    "# We will specifically handle PAD and UNK.\n",
    "embedding_matrix = np.random.normal(scale=0.6, size=(VOCAB_SIZE, EMBEDDING_DIM)).astype(np.float32)\n",
    "# Alternatively, initialize with zeros:\n",
    "# embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM), dtype=np.float32)\n",
    "\n",
    "\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "for word, idx in word_to_idx.items():\n",
    "    if word == PAD_TOKEN:\n",
    "        # Ensure PAD token vector is all zeros\n",
    "        embedding_matrix[idx] = np.zeros(EMBEDDING_DIM, dtype=np.float32)\n",
    "        hits +=1 # Considered a \"hit\" as we intentionally set it\n",
    "    elif word in glove_vectors:\n",
    "        embedding_matrix[idx] = glove_vectors[word]\n",
    "        hits += 1\n",
    "    else:\n",
    "        # Word not in GloVe (or it's the UNK token itself if not in GloVe)\n",
    "        # It will retain its random initialization from above.\n",
    "        # If you initialized with zeros, you might want to assign a specific random vector for UNK here:\n",
    "        # if word == UNK_TOKEN:\n",
    "        #    embedding_matrix[idx] = np.random.normal(scale=0.6, size=(EMBEDDING_DIM, )).astype(np.float32)\n",
    "        misses += 1\n",
    "\n",
    "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")\n",
    "print(f\"Words found in GloVe (hits): {hits}\")\n",
    "print(f\"Words not found in GloVe (misses): {misses} (these will use random initialization or UNK vector)\")\n",
    "\n",
    "# Specifically check the UNK token's embedding (it should be the random init if not in GloVe)\n",
    "if UNK_TOKEN in word_to_idx:\n",
    "    unk_idx = word_to_idx[UNK_TOKEN]\n",
    "    # If UNK_TOKEN was not in GloVe, its vector will be the initially random one.\n",
    "    # If it happened to be in GloVe (unlikely for \"<UNK>\"), it would have the GloVe vector.\n",
    "    print(f\"Vector for UNK token (index {unk_idx}): {embedding_matrix[unk_idx][:10]}...\") # Print first 10 dims\n",
    "else:\n",
    "    print(\"Warning: UNK_TOKEN not found in word_to_idx. This is unexpected.\")\n",
    "\n",
    "if PAD_TOKEN in word_to_idx:\n",
    "     pad_idx = word_to_idx[PAD_TOKEN]\n",
    "     print(f\"Vector for PAD token (index {pad_idx}): {embedding_matrix[pad_idx][:10]}...\")\n",
    "else:\n",
    "    print(\"Warning: PAD_TOKEN not found in word_to_idx. This is unexpected.\")\n",
    "\n",
    "\n",
    "# --- 4. Convert to PyTorch Tensor ---\n",
    "embedding_matrix_tensor = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "print(f\"Embedding matrix converted to PyTorch tensor with shape: {embedding_matrix_tensor.shape}\")\n",
    "\n",
    "# --- (Optional) Save the embedding matrix tensor ---\n",
    "embedding_matrix_path = \"./squad_embedding_matrix_spacy.pt\"\n",
    "print(f\"Saving embedding matrix tensor to {embedding_matrix_path}...\")\n",
    "torch.save(embedding_matrix_tensor, embedding_matrix_path)\n",
    "print(\"Embedding matrix tensor saved.\")\n",
    "\n",
    "# To load it back later:\n",
    "# embedding_matrix_tensor = torch.load(embedding_matrix_path)\n",
    "# print(\"Embedding matrix tensor loaded.\")"
   ],
   "id": "3a4c95cee7e0db63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocabulary from ./squad_vocab_spacy.json...\n",
      "Vocabulary loaded successfully.\n",
      "Vocabulary size: 103963\n",
      "Loading GloVe vectors from ./glove.840B.300d.txt...\n",
      "Loaded 2195884 word vectors from GloVe.\n",
      "Creating embedding matrix...\n",
      "Embedding matrix shape: (103963, 300)\n",
      "Words found in GloVe (hits): 86556\n",
      "Words not found in GloVe (misses): 17407 (these will use random initialization or UNK vector)\n",
      "Vector for UNK token (index 1): [-0.18693003  0.59416074 -0.40828347  0.6995341  -0.15922594  0.29638168\n",
      "  0.30654564 -0.00461517 -0.2958318   0.5320532 ]...\n",
      "Vector for PAD token (index 0): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "Embedding matrix converted to PyTorch tensor with shape: torch.Size([103963, 300])\n",
      "Saving embedding matrix tensor to ./squad_embedding_matrix_spacy.pt...\n",
      "Embedding matrix tensor saved.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T20:50:47.843366Z",
     "start_time": "2025-05-06T20:50:02.521198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from datasets import Dataset # Assuming you're using Hugging Face datasets\n",
    "\n",
    "# --- Configuration ---\n",
    "VOCAB_PATH = \"./squad_vocab_spacy.json\" # Path where you saved your vocabulary\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "# Placeholder maximum lengths -  ADJUST THESE BASED ON YOUR DATA ANALYSIS\n",
    "MAX_CONTEXT_LEN = 512 # Common for SQuAD, but verify\n",
    "MAX_QUESTION_LEN = 60  # Common for SQuAD, but verify\n",
    "\n",
    "# --- 1. Load your vocabulary ---\n",
    "print(f\"Loading vocabulary from {VOCAB_PATH}...\")\n",
    "try:\n",
    "    with open(VOCAB_PATH, 'r') as f:\n",
    "        vocab_data = json.load(f)\n",
    "        word_to_idx = vocab_data['word_to_idx']\n",
    "    print(\"Vocabulary loaded successfully.\")\n",
    "    PAD_ID = word_to_idx[PAD_TOKEN]\n",
    "    UNK_ID = word_to_idx[UNK_TOKEN]\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Vocabulary file not found at {VOCAB_PATH}. Please ensure you've built and saved the vocabulary first.\")\n",
    "    exit()\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Special token {e} not found in vocabulary. Please ensure PAD_TOKEN and UNK_TOKEN are in your vocab.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Load your tokenized datasets (if not already in memory) ---\n",
    "# Replace with your actual loading logic if needed\n",
    "# For demonstration, I'll assume they are loaded as `squad_train_tokenized` and `squad_validation_tokenized`\n",
    "# squad_train_tokenized = Dataset.load_from_disk(\"./squad_train_tokenized_spacy\")\n",
    "# squad_validation_tokenized = Dataset.load_from_disk(\"./squad_validation_tokenized_spacy\")\n",
    "# Make sure these datasets have 'tokenized_context' and 'tokenized_question' columns.\n",
    "\n",
    "# --- 3. Define the processing function ---\n",
    "def numericalize_and_pad(example):\n",
    "    # Numericalize context\n",
    "    context_tokens = example['tokenized_context']\n",
    "    context_ids = [word_to_idx.get(token, UNK_ID) for token in context_tokens]\n",
    "    original_context_len = len(context_ids)\n",
    "\n",
    "    # Numericalize question\n",
    "    question_tokens = example['tokenized_question']\n",
    "    question_ids = [word_to_idx.get(token, UNK_ID) for token in question_tokens]\n",
    "    original_question_len = len(question_ids)\n",
    "\n",
    "    # Pad/Truncate context\n",
    "    if len(context_ids) > MAX_CONTEXT_LEN:\n",
    "        padded_context_ids = context_ids[:MAX_CONTEXT_LEN]\n",
    "    else:\n",
    "        padded_context_ids = context_ids + [PAD_ID] * (MAX_CONTEXT_LEN - len(context_ids))\n",
    "\n",
    "    # Pad/Truncate question\n",
    "    if len(question_ids) > MAX_QUESTION_LEN:\n",
    "        padded_question_ids = question_ids[:MAX_QUESTION_LEN]\n",
    "    else:\n",
    "        padded_question_ids = question_ids + [PAD_ID] * (MAX_QUESTION_LEN - len(question_ids))\n",
    "\n",
    "    return {\n",
    "        'context_ids': padded_context_ids,\n",
    "        'question_ids': padded_question_ids,\n",
    "        'original_context_len': original_context_len, # Store original length\n",
    "        'original_question_len': original_question_len, # Store original length\n",
    "        # Keep answer token indices as they are already token-level\n",
    "        'token_answer_start': example['token_answer_start'],\n",
    "        'token_answer_end': example['token_answer_end'],\n",
    "        'id': example['id'] # Keep id for debugging\n",
    "    }\n",
    "\n",
    "# --- 4. Apply the function to your datasets ---\n",
    "# This assumes squad_train_tokenized and squad_validation_tokenized are loaded\n",
    "# and are Hugging Face Dataset objects.\n",
    "\n",
    "# Dummy datasets for demonstration if you don't have them loaded yet:\n",
    "# This is just to make the script runnable for illustration.\n",
    "# Replace with your actual dataset loading.\n",
    "if 'squad_train_tokenized' not in locals():\n",
    "    print(\"Creating dummy tokenized datasets for demonstration...\")\n",
    "    dummy_data = {\n",
    "        'id': ['1', '2'],\n",
    "        'tokenized_context': [['This', 'is', 'a', 'context', '.'], ['Another', 'example', 'context', 'here', '.']],\n",
    "        'tokenized_question': [['What', 'is', 'this', '?'], ['Example', 'question', '.']],\n",
    "        'token_answer_start': [2, 1],\n",
    "        'token_answer_end': [3, 2]\n",
    "    }\n",
    "    squad_train_tokenized = Dataset.from_dict(dummy_data)\n",
    "    squad_validation_tokenized = Dataset.from_dict(dummy_data)\n",
    "    print(\"Dummy datasets created.\")\n",
    "\n",
    "\n",
    "print(\"Numericalizing and padding training data...\")\n",
    "squad_train_processed = squad_train_tokenized.map(numericalize_and_pad, batched=False)\n",
    "print(\"Numericalizing and padding validation data...\")\n",
    "squad_validation_processed = squad_validation_tokenized.map(numericalize_and_pad, batched=False)\n",
    "\n",
    "# --- 5. Verify the output ---\n",
    "print(\"\\nProcessed training data features:\", squad_train_processed.features)\n",
    "if len(squad_train_processed) > 0:\n",
    "    print(\"\\nFirst example of processed training data:\")\n",
    "    ex = squad_train_processed[0]\n",
    "    print(f\"  Context IDs (first 20): {ex['context_ids'][:20]}...\")\n",
    "    print(f\"  Original Context Length: {ex['original_context_len']}\")\n",
    "    print(f\"  Padded Context Length: {len(ex['context_ids'])}\")\n",
    "    print(f\"  Question IDs (first 20): {ex['question_ids'][:20]}...\")\n",
    "    print(f\"  Original Question Length: {ex['original_question_len']}\")\n",
    "    print(f\"  Padded Question Length: {len(ex['question_ids'])}\")\n",
    "    print(f\"  Answer Start Token: {ex['token_answer_start']}\")\n",
    "    print(f\"  Answer End Token: {ex['token_answer_end']}\")\n",
    "\n",
    "# --- (Optional) Save the processed datasets ---\n",
    "processed_train_path = \"./squad_train_processed_spacy.hf\"\n",
    "processed_validation_path = \"./squad_validation_processed_spacy.hf\"\n",
    "\n",
    "print(f\"\\nSaving processed training data to {processed_train_path}...\")\n",
    "squad_train_processed.save_to_disk(processed_train_path)\n",
    "print(\"Processed training data saved.\")\n",
    "\n",
    "print(f\"Saving processed validation data to {processed_validation_path}...\")\n",
    "squad_validation_processed.save_to_disk(processed_validation_path)\n",
    "print(\"Processed validation data saved.\")\n",
    "\n",
    "# To load them back:\n",
    "# squad_train_processed = Dataset.load_from_disk(processed_train_path)\n",
    "# squad_validation_processed = Dataset.load_from_disk(processed_validation_path)"
   ],
   "id": "1be32027f8493d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocabulary from ./squad_vocab_spacy.json...\n",
      "Vocabulary loaded successfully.\n",
      "Numericalizing and padding training data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd9ec011cef14d10928c80ff2627855e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericalizing and padding validation data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9f06cb9840a4d498647fb27a393f26b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed training data features: {'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None), 'tokenized_context': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'tokenized_question': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'context_token_char_offsets': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'token_answer_start': Value(dtype='int64', id=None), 'token_answer_end': Value(dtype='int64', id=None), 'context_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'question_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'original_context_len': Value(dtype='int64', id=None), 'original_question_len': Value(dtype='int64', id=None)}\n",
      "\n",
      "First example of processed training data:\n",
      "  Context IDs (first 20): [41012, 3, 2, 264, 38, 9, 543, 838, 5, 58109, 2, 5701, 2744, 23, 1550, 7258, 12, 9, 4311, 6569]...\n",
      "  Original Context Length: 142\n",
      "  Padded Context Length: 512\n",
      "  Question IDs (first 20): [547, 851, 49, 2, 3518, 794, 6683, 1347, 7, 7032, 7, 20620, 228, 18, 0, 0, 0, 0, 0, 0]...\n",
      "  Original Question Length: 14\n",
      "  Padded Question Length: 60\n",
      "  Answer Start Token: 102\n",
      "  Answer End Token: 104\n",
      "\n",
      "Saving processed training data to ./squad_train_processed_spacy.hf...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a966a88a7a964b05a4e740a855300cdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training data saved.\n",
      "Saving processed validation data to ./squad_validation_processed_spacy.hf...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1897644849e429e827b9dc2956de935"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed validation data saved.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T21:25:22.972340Z",
     "start_time": "2025-05-06T21:24:44.823706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "from datasets import Dataset # Assuming you're using Hugging Face datasets\n",
    "\n",
    "# --- Configuration for Character Vocabulary ---\n",
    "CHAR_VOCAB_PATH = \"./squad_char_vocab.json\"\n",
    "CHAR_PAD_TOKEN = \"<CHAR_PAD>\" # Padding character for words shorter than MAX_WORD_LEN\n",
    "CHAR_UNK_TOKEN = \"<CHAR_UNK>\" # For unknown characters (less common if vocab built from all data)\n",
    "# MAX_WORD_LEN is defined later, user chose 25\n",
    "\n",
    "# --- Load previously tokenized data (needed to extract words for char vocab) ---\n",
    "# This assumes 'squad_train_tokenized' has 'tokenized_context' and 'tokenized_question'\n",
    "# For demonstration, if not loaded, use a dummy. Replace with your actual loading.\n",
    "# tokenized_train_path = \"./squad_train_tokenized_spacy\"\n",
    "# try:\n",
    "#     squad_train_tokenized_for_char_vocab = Dataset.load_from_disk(tokenized_train_path)\n",
    "#     print(f\"Loaded tokenized training data from {tokenized_train_path} for char vocab building.\")\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"Warning: Tokenized training data not found at {tokenized_train_path}. Using dummy data for char vocab.\")\n",
    "#     squad_train_tokenized_for_char_vocab = Dataset.from_dict({\n",
    "#         'tokenized_context': [['Hello', 'world'], ['Test']],\n",
    "#         'tokenized_question': [['How', 'are', 'you', '?'], ['Why', '?']]\n",
    "#     })\n",
    "\n",
    "def build_char_vocab(tokenized_dataset, special_tokens):\n",
    "    print(\"Building character vocabulary...\")\n",
    "    char_counter = Counter()\n",
    "    for example in tokenized_dataset:\n",
    "        for word in example['tokenized_context']:\n",
    "            char_counter.update(word)\n",
    "        for word in example['tokenized_question']:\n",
    "            char_counter.update(word)\n",
    "\n",
    "    char_to_idx = {token: idx for idx, token in enumerate(special_tokens)}\n",
    "    idx_to_char = {idx: token for token, idx in char_to_idx.items()}\n",
    "\n",
    "    for char, count in char_counter.most_common():\n",
    "        if char not in char_to_idx:\n",
    "            idx = len(char_to_idx)\n",
    "            char_to_idx[char] = idx\n",
    "            idx_to_char[idx] = char\n",
    "\n",
    "    print(f\"Character vocabulary size (including special tokens): {len(char_to_idx)}\")\n",
    "    return char_to_idx, idx_to_char\n",
    "\n",
    "# --- Main script execution for char vocab ---\n",
    "# Assuming squad_train_tokenized is available (e.g., loaded from disk)\n",
    "# Replace this with your actual loading of squad_train_tokenized if needed:\n",
    "# squad_train_tokenized = Dataset.load_from_disk(\"./squad_train_tokenized_spacy\")\n",
    "\n",
    "# For demonstration, let's ensure a dummy `squad_train_tokenized` exists if not loaded:\n",
    "if 'squad_train_tokenized' not in locals():\n",
    "    print(\"Creating dummy 'squad_train_tokenized' for char vocab building demonstration.\")\n",
    "    dummy_data_for_char_vocab = {\n",
    "        'id': ['1', '2'],\n",
    "        'tokenized_context': [['This', 'is', 'a', 'context', 'example-wordlong'], ['Another', 'example', '.']],\n",
    "        'tokenized_question': [['What', 'is', 'this', '?'], ['Example', 'question', '.']],\n",
    "        'token_answer_start': [2, 1],\n",
    "        'token_answer_end': [3, 2]\n",
    "    }\n",
    "    squad_train_tokenized = Dataset.from_dict(dummy_data_for_char_vocab)\n",
    "\n",
    "\n",
    "char_special_tokens = [CHAR_PAD_TOKEN, CHAR_UNK_TOKEN]\n",
    "char_to_idx, idx_to_char = build_char_vocab(squad_train_tokenized, char_special_tokens)\n",
    "\n",
    "print(f\"First 10 chars in vocab: { {k: char_to_idx[k] for k in list(char_to_idx)[:min(10, len(char_to_idx))]} }\")\n",
    "CHAR_PAD_ID = char_to_idx[CHAR_PAD_TOKEN]\n",
    "CHAR_UNK_ID = char_to_idx[CHAR_UNK_TOKEN]\n",
    "print(f\"Character PAD ID: {CHAR_PAD_ID}\")\n",
    "print(f\"Character UNK ID: {CHAR_UNK_ID}\")\n",
    "\n",
    "\n",
    "print(f\"Saving character vocabulary to {CHAR_VOCAB_PATH}...\")\n",
    "with open(CHAR_VOCAB_PATH, 'w') as f:\n",
    "    json.dump({'char_to_idx': char_to_idx, 'idx_to_char': idx_to_char}, f)\n",
    "print(\"Character vocabulary saved.\")\n",
    "\n",
    "# For later use:\n",
    "# with open(CHAR_VOCAB_PATH, 'r') as f:\n",
    "#     char_vocab_data = json.load(f)\n",
    "#     char_to_idx = char_vocab_data['char_to_idx']\n",
    "#     idx_to_char = char_vocab_data['idx_to_char']\n",
    "#     CHAR_PAD_ID = char_to_idx[CHAR_PAD_TOKEN]\n",
    "#     CHAR_UNK_ID = char_to_idx[CHAR_UNK_TOKEN]"
   ],
   "id": "f01890cca8c0ee36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building character vocabulary...\n",
      "Character vocabulary size (including special tokens): 1374\n",
      "First 10 chars in vocab: {'<CHAR_PAD>': 0, '<CHAR_UNK>': 1, 'e': 2, 't': 3, 'a': 4, 'i': 5, 'n': 6, 'o': 7, 'r': 8, 's': 9}\n",
      "Character PAD ID: 0\n",
      "Character UNK ID: 1\n",
      "Saving character vocabulary to ./squad_char_vocab.json...\n",
      "Character vocabulary saved.\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T22:52:18.283782Z",
     "start_time": "2025-05-06T22:47:21.376048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch # Not strictly needed here, but often imported together\n",
    "from datasets import Dataset # Already imported\n",
    "import json\n",
    "\n",
    "CHAR_VOCAB_PATH = \"./squad_char_vocab.json\"\n",
    "CHAR_PAD_TOKEN = \"<CHAR_PAD>\" # Padding character for words shorter than MAX_WORD_LEN\n",
    "CHAR_UNK_TOKEN = \"<CHAR_UNK>\" # For unknown characters (less common if vocab built from all data)\n",
    "\n",
    "# --- Configuration & Hyperparameters ---\n",
    "# Paths (ensure these match your saved files)\n",
    "PROCESSED_TRAIN_PATH = \"./squad_train_processed_char.hf\"\n",
    "PROCESSED_VALIDATION_PATH = \"./squad_validation_processed_char.hf\"\n",
    "WORD_VOCAB_PATH = \"./squad_vocab_spacy.json\"\n",
    "CHAR_VOCAB_PATH = \"./squad_char_vocab.json\"\n",
    "PRETRAINED_WORD_EMB_PATH = \"./squad_embedding_matrix_spacy.pt\" # GloVe matrix\n",
    "\n",
    "# Model & Embedding Hyperparameters (should match your model definition)\n",
    "# Word Embeddings\n",
    "WORD_EMBEDDING_DIM = 300 # User specified\n",
    "# Character Embeddings (based on BiDAF paper / common practice)\n",
    "CHAR_EMBEDDING_DIM = 8    # Dimension of individual char embedding\n",
    "CHAR_CNN_OUT_CHANNELS = 100 # Output dim of char CNN, effectively char-level word emb dim\n",
    "CHAR_CNN_KERNEL_SIZE = 5\n",
    "# Model Structure\n",
    "HIDDEN_SIZE = 300 # 'd' in BiDAF paper, often same as word_embedding_dim\n",
    "NUM_HIGHWAY_LAYERS = 2\n",
    "DROPOUT_RATE = 0.2\n",
    "# MAX_WORD_LEN = 25 # Defined during preprocessing\n",
    "\n",
    "# Training Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 10 # Adjust based on your GPU memory\n",
    "NUM_EPOCHS = 10 # Start with a few, increase later\n",
    "CLIP_GRAD_NORM = 5.0 # For gradient clipping\n",
    "\n",
    "squad_train_tokenized = Dataset.load_from_disk(\"./squad_train_tokenized_spacy\")\n",
    "squad_validation_tokenized = Dataset.load_from_disk(\"./squad_validation_tokenized_spacy\") # or however you load it\n",
    "\n",
    "# --- Configuration from previous steps (ensure these are loaded/defined) ---\n",
    "WORD_VOCAB_PATH = \"./squad_vocab_spacy.json\" # Path to your word vocabulary\n",
    "# CHAR_VOCAB_PATH is defined above\n",
    "WORD_PAD_TOKEN = \"<PAD>\"\n",
    "WORD_UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "MAX_CONTEXT_LEN = 512  # User specified\n",
    "MAX_QUESTION_LEN = 60 # User specified\n",
    "MAX_WORD_LEN = 25      # User specified\n",
    "\n",
    "# --- Load Word Vocabulary ---\n",
    "print(f\"Loading word vocabulary from {WORD_VOCAB_PATH}...\")\n",
    "try:\n",
    "    with open(WORD_VOCAB_PATH, 'r') as f:\n",
    "        word_vocab_data = json.load(f)\n",
    "        word_to_idx = word_vocab_data['word_to_idx']\n",
    "    WORD_PAD_ID = word_to_idx[WORD_PAD_TOKEN]\n",
    "    WORD_UNK_ID = word_to_idx[WORD_UNK_TOKEN]\n",
    "    print(\"Word vocabulary loaded.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Word vocabulary file not found at {WORD_VOCAB_PATH}.\")\n",
    "    exit()\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Word special token {e} not found in word vocabulary.\")\n",
    "    exit()\n",
    "\n",
    "# --- Load Character Vocabulary (built in Part 1 or loaded if exists) ---\n",
    "print(f\"Loading character vocabulary from {CHAR_VOCAB_PATH}...\")\n",
    "try:\n",
    "    with open(CHAR_VOCAB_PATH, 'r') as f:\n",
    "        char_vocab_data = json.load(f)\n",
    "        char_to_idx = char_vocab_data['char_to_idx']\n",
    "    CHAR_PAD_ID = char_to_idx[CHAR_PAD_TOKEN]\n",
    "    CHAR_UNK_ID = char_to_idx[CHAR_UNK_TOKEN] # Ensure this was created if needed\n",
    "    print(\"Character vocabulary loaded.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Character vocabulary file not found at {CHAR_VOCAB_PATH}.\")\n",
    "    exit()\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Character special token {e} not found in character vocabulary.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "def process_tokens_for_model(tokens, max_tokens_len, word_to_idx_local, char_to_idx_local,\n",
    "                             max_word_len_local, word_pad_id_local, word_unk_id_local,\n",
    "                             char_pad_id_local, char_unk_id_local):\n",
    "    # 1. Word ID processing\n",
    "    word_ids = [word_to_idx_local.get(token, word_unk_id_local) for token in tokens]\n",
    "    original_len = len(word_ids) # True length of word tokens\n",
    "\n",
    "    # Pad/Truncate word IDs\n",
    "    if len(word_ids) > max_tokens_len:\n",
    "        padded_word_ids = word_ids[:max_tokens_len]\n",
    "    else:\n",
    "        padded_word_ids = word_ids + [word_pad_id_local] * (max_tokens_len - len(word_ids))\n",
    "\n",
    "    # 2. Character ID processing\n",
    "    char_ids_for_words = []\n",
    "    # Iterate up to the potentially truncated number of words (max_tokens_len)\n",
    "    # but use original_len to access actual tokens\n",
    "    num_words_to_process_chars_for = min(original_len, max_tokens_len)\n",
    "\n",
    "    for i in range(max_tokens_len):\n",
    "        if i < num_words_to_process_chars_for: # If it's an actual word within the (potentially truncated) sequence\n",
    "            word = tokens[i] # Access from original tokens list\n",
    "            current_word_char_ids = [char_to_idx_local.get(char, char_unk_id_local) for char in word]\n",
    "            if len(current_word_char_ids) > max_word_len_local:\n",
    "                padded_word_char_ids = current_word_char_ids[:max_word_len_local]\n",
    "            else:\n",
    "                padded_word_char_ids = current_word_char_ids + [char_pad_id_local] * (max_word_len_local - len(current_word_char_ids))\n",
    "        else: # It's a padding word slot (either original padding or due to context truncation)\n",
    "            padded_word_char_ids = [char_pad_id_local] * max_word_len_local\n",
    "        char_ids_for_words.append(padded_word_char_ids)\n",
    "\n",
    "    return padded_word_ids, char_ids_for_words, original_len\n",
    "\n",
    "\n",
    "def full_preprocess_function(example):\n",
    "    # Process context\n",
    "    context_word_ids, context_char_ids, original_context_len = process_tokens_for_model(\n",
    "        tokens=example['tokenized_context'],\n",
    "        max_tokens_len=MAX_CONTEXT_LEN,\n",
    "        word_to_idx_local=word_to_idx, # Make sure word_to_idx is accessible\n",
    "        char_to_idx_local=char_to_idx,   # Make sure char_to_idx is accessible\n",
    "        max_word_len_local=MAX_WORD_LEN,\n",
    "        word_pad_id_local=WORD_PAD_ID, # Make sure WORD_PAD_ID is accessible\n",
    "        word_unk_id_local=WORD_UNK_ID, # Make sure WORD_UNK_ID is accessible\n",
    "        char_pad_id_local=CHAR_PAD_ID, # Make sure CHAR_PAD_ID is accessible\n",
    "        char_unk_id_local=CHAR_UNK_ID  # Make sure CHAR_UNK_ID is accessible\n",
    "    )\n",
    "\n",
    "    # Process question\n",
    "    question_word_ids, question_char_ids, original_question_len = process_tokens_for_model(\n",
    "        tokens=example['tokenized_question'],\n",
    "        max_tokens_len=MAX_QUESTION_LEN,\n",
    "        word_to_idx_local=word_to_idx,\n",
    "        char_to_idx_local=char_to_idx,\n",
    "        max_word_len_local=MAX_WORD_LEN,\n",
    "        word_pad_id_local=WORD_PAD_ID,\n",
    "        word_unk_id_local=WORD_UNK_ID,\n",
    "        char_pad_id_local=CHAR_PAD_ID,\n",
    "        char_unk_id_local=CHAR_UNK_ID\n",
    "    )\n",
    "\n",
    "    # Get original answer token indices from the example\n",
    "    # These were computed based on the original (untruncated) tokenized_context\n",
    "    ans_start_orig = example['token_answer_start']\n",
    "    ans_end_orig = example['token_answer_end']\n",
    "\n",
    "    final_ans_start = ans_start_orig\n",
    "    final_ans_end = ans_end_orig\n",
    "\n",
    "    # Check if the original answer indices are valid *after* context truncation to MAX_CONTEXT_LEN\n",
    "    # The logits produced by the model will have a dimension of MAX_CONTEXT_LEN.\n",
    "    # So, target indices must be < MAX_CONTEXT_LEN.\n",
    "    if ans_start_orig != -1 : # Check if it was a validly mapped answer initially\n",
    "        if ans_start_orig >= MAX_CONTEXT_LEN or ans_end_orig >= MAX_CONTEXT_LEN:\n",
    "            # If the start or end of the answer falls outside the truncated context length\n",
    "            print(f\"WARNING: Example {example['id']}: Original answer span ({ans_start_orig}, {ans_end_orig}) \"\n",
    "                  f\"is partially or fully outside MAX_CONTEXT_LEN ({MAX_CONTEXT_LEN}). \"\n",
    "                  f\"Marking this example's answer to be ignored by loss function.\")\n",
    "            final_ans_start = -1  # To be ignored by CrossEntropyLoss(ignore_index=-1)\n",
    "            final_ans_end = -1    # To be ignored by CrossEntropyLoss\n",
    "        # Optional: a further sanity check if end somehow became less than start after some logic\n",
    "        # Though with the above, if start is valid, end should be >= start unless original data was flawed\n",
    "        # or original mapping set end < start for some reason.\n",
    "        # if final_ans_start != -1 and final_ans_end < final_ans_start:\n",
    "        #    print(f\"WARNING: Example {example['id']}: Corrected ans_end ({final_ans_end}) < ans_start ({final_ans_start}). Setting to ignore.\")\n",
    "        #    final_ans_start = -1\n",
    "        #    final_ans_end = -1\n",
    "\n",
    "    # If ans_start_orig was already -1 (e.g., from an earlier \"could not map\" warning),\n",
    "    # final_ans_start and final_ans_end will remain -1.\n",
    "\n",
    "    return {\n",
    "        'context_ids': context_word_ids,\n",
    "        'context_char_ids': context_char_ids,\n",
    "        'original_context_len': original_context_len,\n",
    "\n",
    "        'question_ids': question_word_ids,\n",
    "        'question_char_ids': question_char_ids,\n",
    "        'original_question_len': original_question_len,\n",
    "\n",
    "        'token_answer_start': final_ans_start, # Use the potentially adjusted values\n",
    "        'token_answer_end': final_ans_end,   # Use the potentially adjusted values\n",
    "        'id': example['id']\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Apply to your datasets ---\n",
    "# This assumes 'squad_train_tokenized' and 'squad_validation_tokenized' are loaded\n",
    "# and are Hugging Face Dataset objects from the spaCy tokenization step.\n",
    "# (Using the dummy `squad_train_tokenized` from Part 1 if no real one is loaded)\n",
    "\n",
    "print(\"\\nApplying full preprocessing (word & char) to training data...\")\n",
    "squad_train_processed_with_chars = squad_train_tokenized.map(full_preprocess_function, batched=False)\n",
    "print(\"Applying full preprocessing (word & char) to validation data...\")\n",
    "# Ensure squad_validation_tokenized is loaded or defined similarly if you're running this standalone\n",
    "if 'squad_validation_tokenized' not in locals():\n",
    "    print(\"Creating dummy 'squad_validation_tokenized' for demonstration.\")\n",
    "    squad_validation_tokenized = Dataset.from_dict(squad_train_tokenized.to_dict()) # Just duplicate for now\n",
    "\n",
    "squad_validation_processed_with_chars = squad_validation_tokenized.map(full_preprocess_function, batched=False)\n",
    "\n",
    "\n",
    "# --- Verify the output ---\n",
    "print(\"\\nProcessed training data (with chars) features:\", squad_train_processed_with_chars.features)\n",
    "if len(squad_train_processed_with_chars) > 0:\n",
    "    ex = squad_train_processed_with_chars[0]\n",
    "    print(\"\\nFirst example of processed training data (with chars):\")\n",
    "    print(f\"  Context IDs (word level, first 10): {ex['context_ids'][:10]}...\")\n",
    "    print(f\"  Context Char IDs (shape for first word): {np.array(ex['context_char_ids'][0]).shape if ex['context_char_ids'] else 'N/A'}\")\n",
    "    print(f\"  Context Char IDs (first word, first 10 chars): {ex['context_char_ids'][0][:10] if ex['context_char_ids'] else 'N/A'}...\")\n",
    "    print(f\"  Shape of context_char_ids field: {np.array(ex['context_char_ids']).shape}\")\n",
    "    print(f\"  Original Context Length (words): {ex['original_context_len']}\")\n",
    "    print(f\"  Padded Context Length (words): {len(ex['context_ids'])}\")\n",
    "\n",
    "    print(f\"  Question IDs (word level, first 10): {ex['question_ids'][:10]}...\")\n",
    "    print(f\"  Shape of question_char_ids field: {np.array(ex['question_char_ids']).shape}\")\n",
    "    print(f\"  Original Question Length (words): {ex['original_question_len']}\")\n",
    "\n",
    "    print(f\"  Answer Start Token: {ex['token_answer_start']}\")\n",
    "    print(f\"  Answer End Token: {ex['token_answer_end']}\")\n",
    "\n",
    "# --- (Optional) Save the fully processed datasets ---\n",
    "processed_train_char_path = \"./squad_train_processed_char.hf\"\n",
    "processed_validation_char_path = \"./squad_validation_processed_char.hf\"\n",
    "\n",
    "print(f\"\\nSaving fully processed training data to {processed_train_char_path}...\")\n",
    "squad_train_processed_with_chars.save_to_disk(processed_train_char_path)\n",
    "print(\"Fully processed training data saved.\")\n",
    "\n",
    "print(f\"Saving fully processed validation data to {processed_validation_char_path}...\")\n",
    "squad_validation_processed_with_chars.save_to_disk(processed_validation_char_path)\n",
    "print(\"Fully processed validation data saved.\")"
   ],
   "id": "833dea0d3614a867",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vocabulary from ./squad_vocab_spacy.json...\n",
      "Word vocabulary loaded.\n",
      "Loading character vocabulary from ./squad_char_vocab.json...\n",
      "Character vocabulary loaded.\n",
      "\n",
      "Applying full preprocessing (word & char) to training data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "714cd501b37f47dd8da6f5d2e205e174"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Example 56cef51daab44d1400b88d14: Original answer span (608, 608) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 5727e311ff5b5019007d9798: Original answer span (526, 538) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 5727e311ff5b5019007d9799: Original answer span (596, 602) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 5727e311ff5b5019007d979a: Original answer span (631, 633) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 5727e311ff5b5019007d979b: Original answer span (625, 625) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 5727e311ff5b5019007d979c: Original answer span (616, 621) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 5728c4163acd2414000dfde0: Original answer span (556, 558) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 5728c4163acd2414000dfde3: Original answer span (589, 596) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "Applying full preprocessing (word & char) to validation data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e85997ecd90a45f99403ba486a5f8eb0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Example 572651f9f1498d1400e8dbf2: Original answer span (524, 527) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 5726bc1add62a815002e8eaa: Original answer span (530, 536) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 57263b1638643c19005ad335: Original answer span (516, 545) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 57263b1638643c19005ad334: Original answer span (494, 516) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "WARNING: Example 57263b1638643c19005ad336: Original answer span (553, 566) is partially or fully outside MAX_CONTEXT_LEN (512). Marking this example's answer to be ignored by loss function.\n",
      "\n",
      "Processed training data (with chars) features: {'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None), 'tokenized_context': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'tokenized_question': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'context_token_char_offsets': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'token_answer_start': Value(dtype='int64', id=None), 'token_answer_end': Value(dtype='int64', id=None), 'context_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'context_char_ids': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None), 'original_context_len': Value(dtype='int64', id=None), 'question_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'question_char_ids': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None), 'original_question_len': Value(dtype='int64', id=None)}\n",
      "\n",
      "First example of processed training data (with chars):\n",
      "  Context IDs (word level, first 10): [41012, 3, 2, 264, 38, 9, 543, 838, 5, 58109]...\n",
      "  Context Char IDs (shape for first word): (25,)\n",
      "  Context Char IDs (first word, first 10 chars): [29, 8, 13, 10, 5, 3, 2, 13, 3, 14]...\n",
      "  Shape of context_char_ids field: (512, 25)\n",
      "  Original Context Length (words): 142\n",
      "  Padded Context Length (words): 512\n",
      "  Question IDs (word level, first 10): [547, 851, 49, 2, 3518, 794, 6683, 1347, 7, 7032]...\n",
      "  Shape of question_char_ids field: (60, 25)\n",
      "  Original Question Length (words): 14\n",
      "  Answer Start Token: 102\n",
      "  Answer End Token: 104\n",
      "\n",
      "Saving fully processed training data to ./squad_train_processed_char.hf...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/22 shards):   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb3340575e794fb59c6be8277f8439bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully processed training data saved.\n",
      "Saving fully processed validation data to ./squad_validation_processed_char.hf...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b924085a3cad4da08d8770c8072174ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully processed validation data saved.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T06:29:53.845116Z",
     "start_time": "2025-05-07T06:29:45.578476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CharEmbedding(nn.Module):\n",
    "    def __init__(self, char_vocab_size, char_embedding_dim, char_cnn_out_channels,\n",
    "                 char_cnn_kernel_size, char_padding_idx, dropout_rate):\n",
    "        super(CharEmbedding, self).__init__()\n",
    "\n",
    "        self.char_embedding = nn.Embedding(\n",
    "            num_embeddings=char_vocab_size,\n",
    "            embedding_dim=char_embedding_dim,\n",
    "            padding_idx=char_padding_idx\n",
    "        )\n",
    "\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=char_embedding_dim,\n",
    "            out_channels=char_cnn_out_channels,\n",
    "            kernel_size=char_cnn_kernel_size,\n",
    "            # Padding to maintain length for easier max-pooling across the sequence dimension later,\n",
    "            # or use specific padding based on kernel size.\n",
    "            # For kernel_size=5, padding=2 would keep length same if stride=1.\n",
    "        )\n",
    "        # The paper implies max-pooling over the resulting length of the convolution for each word.\n",
    "        # If conv output length is L_out = L_in - kernel_size + 1 + 2*padding.\n",
    "        # Let's use padding such that the output length is reasonable.\n",
    "        # A common approach: padding = (kernel_size - 1) // 2 for 'same' style padding.\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x_char_ids):\n",
    "        # x_char_ids: (batch_size, seq_len, max_word_len)\n",
    "        batch_size, seq_len, max_word_len = x_char_ids.shape\n",
    "\n",
    "        # Reshape for embedding: (batch_size * seq_len, max_word_len)\n",
    "        x_char_ids_reshaped = x_char_ids.view(-1, max_word_len)\n",
    "\n",
    "        # Embed characters: (batch_size * seq_len, max_word_len, char_embedding_dim)\n",
    "        char_emb = self.char_embedding(x_char_ids_reshaped)\n",
    "        char_emb = self.dropout(char_emb) # Apply dropout to character embeddings\n",
    "\n",
    "        # Permute for Conv1d: (batch_size * seq_len, char_embedding_dim, max_word_len)\n",
    "        char_emb_permuted = char_emb.permute(0, 2, 1)\n",
    "\n",
    "        # Convolution: (batch_size * seq_len, char_cnn_out_channels, convolved_len)\n",
    "        # The convolved_len depends on max_word_len, kernel_size, and padding.\n",
    "        # Example: if max_word_len=16, kernel=5, padding=0 -> convolved_len = 16-5+1 = 12\n",
    "        # Example: if max_word_len=16, kernel=5, padding=2 -> convolved_len = 16-5+1+2*2 = 16\n",
    "        char_conv_out = self.conv1d(char_emb_permuted)\n",
    "        char_conv_out = F.relu(char_conv_out) # Apply ReLU\n",
    "\n",
    "        # Max-pool over the convolved length dimension: (batch_size * seq_len, char_cnn_out_channels)\n",
    "        # The kernel_size for max_pool1d should be the full length of the convolved dimension.\n",
    "        char_pooled = F.max_pool1d(char_conv_out, kernel_size=char_conv_out.shape[2]).squeeze(2)\n",
    "\n",
    "        # Reshape back to (batch_size, seq_len, char_cnn_out_channels)\n",
    "        final_char_emb = char_pooled.view(batch_size, seq_len, -1)\n",
    "\n",
    "        return final_char_emb\n",
    "\n",
    "\n",
    "# HighwayNetwork class remains the same as provided in the previous full model response\n",
    "class HighwayNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers):\n",
    "        super(HighwayNetwork, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.transform_gates = nn.ModuleList([nn.Linear(input_dim, input_dim) for _ in range(num_layers)])\n",
    "        self.normal_layers = nn.ModuleList([nn.Linear(input_dim, input_dim) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_layers):\n",
    "            transform_gate_output = torch.sigmoid(self.transform_gates[i](x))\n",
    "            normal_layer_output = F.relu(self.normal_layers[i](x))\n",
    "            x = transform_gate_output * normal_layer_output + (1 - transform_gate_output) * x\n",
    "        return x\n",
    "\n",
    "# BiDAFAttention class remains the same as provided in the previous full model response\n",
    "class BiDAFAttention(nn.Module):\n",
    "    def __init__(self, hidden_size_times_2d): # effectively 2 * d, e.g., 2 * 300 = 600\n",
    "        super(BiDAFAttention, self).__init__()\n",
    "        self.hidden_size_times_2d = hidden_size_times_2d\n",
    "        self.similarity_weight = nn.Linear(self.hidden_size_times_2d * 3, 1, bias=False)\n",
    "\n",
    "    def forward(self, C_contextual, Q_contextual, C_mask, Q_mask):\n",
    "        # C_contextual: (batch, C_len, 2d)\n",
    "        # Q_contextual: (batch, Q_len, 2d)\n",
    "        batch_size, C_len, _ = C_contextual.shape\n",
    "        _, Q_len, _ = Q_contextual.shape\n",
    "\n",
    "        C_expanded = C_contextual.unsqueeze(2).expand(-1, -1, Q_len, -1)\n",
    "        Q_expanded = Q_contextual.unsqueeze(1).expand(-1, C_len, -1, -1)\n",
    "        elementwise_prod = C_expanded * Q_expanded\n",
    "        concat_features = torch.cat((C_expanded, Q_expanded, elementwise_prod), dim=3)\n",
    "        S = self.similarity_weight(concat_features).squeeze(3)\n",
    "\n",
    "        S_masked_q = S.masked_fill(Q_mask.unsqueeze(1) == 0, -float('inf'))\n",
    "        S_masked_c = S.masked_fill(C_mask.unsqueeze(2) == 0, -float('inf'))\n",
    "\n",
    "        alpha = F.softmax(S_masked_q, dim=2)\n",
    "        A = torch.bmm(alpha, Q_contextual)\n",
    "\n",
    "        max_S_c = torch.max(S, dim=2)[0]\n",
    "        max_S_c_masked = max_S_c.masked_fill(C_mask == 0, -float('inf'))\n",
    "        b_weights = F.softmax(max_S_c_masked, dim=1)\n",
    "        C_prime = torch.bmm(b_weights.unsqueeze(1), C_contextual).squeeze(1)\n",
    "        B = C_prime.unsqueeze(1).expand(-1, C_len, -1)\n",
    "\n",
    "        g_c_a = C_contextual * A\n",
    "        g_c_b = C_contextual * B\n",
    "        G = torch.cat((C_contextual, A, g_c_a, g_c_b), dim=2)\n",
    "        return G\n",
    "\n",
    "\n",
    "class BiDAF(nn.Module):\n",
    "    def __init__(self,\n",
    "                 # Word embedding params\n",
    "                 word_vocab_size, word_embedding_dim, pretrained_word_embeddings, word_padding_idx,\n",
    "                 # Character embedding params\n",
    "                 char_vocab_size, char_embedding_dim, char_cnn_out_channels,\n",
    "                 char_cnn_kernel_size, char_padding_idx,\n",
    "                 # Model general params\n",
    "                 hidden_size, # This is 'd' in the paper, e.g., 300\n",
    "                 num_highway_layers=2, dropout_rate=0.2):\n",
    "        super(BiDAF, self).__init__()\n",
    "\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "        self.char_output_dim = char_cnn_out_channels\n",
    "        self.combined_embedding_dim = self.word_embedding_dim + self.char_output_dim # e.g., 300 + 100 = 400\n",
    "\n",
    "        self.hidden_size = hidden_size # d (e.g., 300)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.word_padding_idx = word_padding_idx\n",
    "\n",
    "        # 1. Word Embedding Layer\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(\n",
    "            embeddings=pretrained_word_embeddings,\n",
    "            freeze=False, # Set to False to fine-tune GloVe embeddings\n",
    "            padding_idx=self.word_padding_idx\n",
    "        )\n",
    "\n",
    "        # 1b. Character Embedding Layer\n",
    "        self.char_embedding_layer = CharEmbedding(\n",
    "            char_vocab_size=char_vocab_size,\n",
    "            char_embedding_dim=char_embedding_dim, # e.g., 8 or 20\n",
    "            char_cnn_out_channels=self.char_output_dim, # e.g., 100\n",
    "            char_cnn_kernel_size=char_cnn_kernel_size, # e.g., 5\n",
    "            char_padding_idx=char_padding_idx,\n",
    "            dropout_rate=self.dropout_rate\n",
    "        )\n",
    "\n",
    "        # 2. Highway Network\n",
    "        # Input is the concatenated word and char embeddings\n",
    "        self.highway_network = HighwayNetwork(input_dim=self.combined_embedding_dim, num_layers=num_highway_layers)\n",
    "\n",
    "        # 3. Contextual Embedding Layer (BiLSTM)\n",
    "        # Input: combined_embedding_dim (e.g., 400)\n",
    "        # Output: 2 * hidden_size (e.g., 2 * 300 = 600) because bidirectional\n",
    "        self.contextual_lstm = nn.LSTM(\n",
    "            input_size=self.combined_embedding_dim,\n",
    "            hidden_size=self.hidden_size, # d\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=0 # Dropout between LSTM layers only if num_layers > 1; we apply manually after\n",
    "        )\n",
    "\n",
    "        # 4. Attention Flow Layer\n",
    "        # Input features to attention are of size 2*hidden_size (output of contextual_lstm)\n",
    "        self.attention = BiDAFAttention(hidden_size_times_2d=2 * self.hidden_size)\n",
    "\n",
    "        # 5. Modeling Layer (BiLSTM)\n",
    "        # Input: 8 * hidden_size (output of attention G, since G contains 4 components each of size 2*hidden_size)\n",
    "        # Output: 2 * hidden_size\n",
    "        self.modeling_lstm = nn.LSTM(\n",
    "            input_size=8 * self.hidden_size, # Each of the 4 components in G is 2*hidden_size\n",
    "            hidden_size=self.hidden_size, # d\n",
    "            num_layers=2, # As per paper\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=self.dropout_rate if 2 > 1 else 0 # LSTM internal dropout\n",
    "        )\n",
    "\n",
    "        # 6. Output Layer\n",
    "        # Predicts start and end logits\n",
    "        # Input for prediction: concat(G, M) -> (8*hidden_size + 2*hidden_size) = 10 * hidden_size\n",
    "        self.start_output_linear = nn.Linear(10 * self.hidden_size, 1)\n",
    "        self.end_output_linear = nn.Linear(10 * self.hidden_size, 1)\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(self.dropout_rate)\n",
    "\n",
    "\n",
    "    def forward(self, context_word_ids, question_word_ids, context_char_ids, question_char_ids):\n",
    "        # context_word_ids: (batch, C_len)\n",
    "        # question_word_ids: (batch, Q_len)\n",
    "        # context_char_ids: (batch, C_len, max_word_len)\n",
    "        # question_char_ids: (batch, Q_len, max_word_len)\n",
    "\n",
    "        # Masks (1 for tokens, 0 for padding)\n",
    "        C_mask = (context_word_ids != self.word_padding_idx)\n",
    "        Q_mask = (question_word_ids != self.word_padding_idx)\n",
    "\n",
    "        # 1a. Word Embedding\n",
    "        C_word_emb = self.word_embedding(context_word_ids)    # (batch, C_len, word_emb_dim)\n",
    "        Q_word_emb = self.word_embedding(question_word_ids)  # (batch, Q_len, word_emb_dim)\n",
    "\n",
    "        # 1b. Character Embedding\n",
    "        C_char_emb = self.char_embedding_layer(context_char_ids) # (batch, C_len, char_output_dim)\n",
    "        Q_char_emb = self.char_embedding_layer(question_char_ids)# (batch, Q_len, char_output_dim)\n",
    "\n",
    "        # Concatenate word and char embeddings\n",
    "        C_emb_combined = torch.cat((C_word_emb, C_char_emb), dim=2) # (batch, C_len, combined_emb_dim)\n",
    "        Q_emb_combined = torch.cat((Q_word_emb, Q_char_emb), dim=2) # (batch, Q_len, combined_emb_dim)\n",
    "\n",
    "        C_emb_combined = self.dropout_layer(C_emb_combined)\n",
    "        Q_emb_combined = self.dropout_layer(Q_emb_combined)\n",
    "\n",
    "        # 2. Highway Network\n",
    "        C_highway = self.highway_network(C_emb_combined)     # (batch, C_len, combined_emb_dim)\n",
    "        Q_highway = self.highway_network(Q_emb_combined)   # (batch, Q_len, combined_emb_dim)\n",
    "\n",
    "        # 3. Contextual Embedding Layer (BiLSTM)\n",
    "        # Input: combined_emb_dim, Output: (batch, seq_len, 2*hidden_size)\n",
    "        C_contextual, _ = self.contextual_lstm(C_highway)\n",
    "        Q_contextual, _ = self.contextual_lstm(Q_highway)\n",
    "\n",
    "        C_contextual = self.dropout_layer(C_contextual)\n",
    "        Q_contextual = self.dropout_layer(Q_contextual)\n",
    "\n",
    "        # 4. Attention Flow Layer\n",
    "        # G: (batch, C_len, 8*hidden_size)\n",
    "        G = self.attention(C_contextual, Q_contextual, C_mask.float(), Q_mask.float())\n",
    "        G = self.dropout_layer(G) # Dropout after attention output\n",
    "\n",
    "        # 5. Modeling Layer (BiLSTM)\n",
    "        # M: (batch, C_len, 2*hidden_size)\n",
    "        M, _ = self.modeling_lstm(G)\n",
    "        M = self.dropout_layer(M) # Dropout after modeling layer output\n",
    "\n",
    "        # 6. Output Layer\n",
    "        output_features = torch.cat((G, M), dim=2) # (batch, C_len, 10*hidden_size)\n",
    "\n",
    "        start_logits = self.start_output_linear(output_features).squeeze(2) # (batch, C_len)\n",
    "        end_logits = self.end_output_linear(output_features).squeeze(2)   # (batch, C_len)\n",
    "\n",
    "        start_logits_masked = start_logits.masked_fill(C_mask == 0, -float('inf'))\n",
    "        end_logits_masked = end_logits.masked_fill(C_mask == 0, -float('inf'))\n",
    "\n",
    "        return start_logits_masked, end_logits_masked\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, load_from_disk\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm # For progress bars\n",
    "\n",
    "# --- Configuration & Hyperparameters ---\n",
    "# Paths (ensure these match your saved files)\n",
    "PROCESSED_TRAIN_PATH = \"./squad_train_processed_char.hf\"\n",
    "PROCESSED_VALIDATION_PATH = \"./squad_validation_processed_char.hf\"\n",
    "WORD_VOCAB_PATH = \"./squad_vocab_spacy.json\"\n",
    "CHAR_VOCAB_PATH = \"./squad_char_vocab.json\"\n",
    "PRETRAINED_WORD_EMB_PATH = \"./squad_embedding_matrix_spacy.pt\" # GloVe matrix\n",
    "\n",
    "# Model & Embedding Hyperparameters (should match your model definition)\n",
    "# Word Embeddings\n",
    "WORD_EMBEDDING_DIM = 300 # User specified\n",
    "# Character Embeddings (based on BiDAF paper / common practice)\n",
    "CHAR_EMBEDDING_DIM = 8    # Dimension of individual char embedding\n",
    "CHAR_CNN_OUT_CHANNELS = 50 # Output dim of char CNN, effectively char-level word emb dim\n",
    "CHAR_CNN_KERNEL_SIZE = 5\n",
    "# Model Structure\n",
    "HIDDEN_SIZE = 128 # 'd' in BiDAF paper, often same as word_embedding_dim\n",
    "NUM_HIGHWAY_LAYERS = 2\n",
    "DROPOUT_RATE = 0.2\n",
    "# MAX_WORD_LEN = 25 # Defined during preprocessing\n",
    "\n",
    "# Training Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 24 # Adjust based on your GPU memory\n",
    "NUM_EPOCHS = 10 # Start with a few, increase later\n",
    "CLIP_GRAD_NORM = 5.0 # For gradient clipping\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Load Vocabularies and Pretrained Embeddings ---\n",
    "try:\n",
    "    with open(WORD_VOCAB_PATH, 'r') as f:\n",
    "        word_vocab_data = json.load(f)\n",
    "        word_to_idx = word_vocab_data['word_to_idx']\n",
    "    WORD_VOCAB_SIZE = len(word_to_idx)\n",
    "    WORD_PADDING_IDX = word_to_idx.get(\"<PAD>\", 0) # Ensure your PAD token name\n",
    "    print(f\"Word vocabulary loaded. Size: {WORD_VOCAB_SIZE}, PAD_IDX: {WORD_PADDING_IDX}\")\n",
    "\n",
    "    with open(CHAR_VOCAB_PATH, 'r') as f:\n",
    "        char_vocab_data = json.load(f)\n",
    "        char_to_idx = char_vocab_data['char_to_idx']\n",
    "    CHAR_VOCAB_SIZE = len(char_to_idx)\n",
    "    CHAR_PADDING_IDX = char_to_idx.get(\"<CHAR_PAD>\", 0) # Ensure your CHAR_PAD token name\n",
    "    print(f\"Character vocabulary loaded. Size: {CHAR_VOCAB_SIZE}, CHAR_PAD_IDX: {CHAR_PADDING_IDX}\")\n",
    "\n",
    "    pretrained_word_embeddings = torch.load(PRETRAINED_WORD_EMB_PATH, map_location=device)\n",
    "    # Verify embedding dim if necessary, should be WORD_EMBEDDING_DIM\n",
    "    print(f\"Pretrained word embeddings loaded. Shape: {pretrained_word_embeddings.shape}\")\n",
    "    if pretrained_word_embeddings.shape[1] != WORD_EMBEDDING_DIM:\n",
    "        raise ValueError(f\"Pretrained embedding dim ({pretrained_word_embeddings.shape[1]}) != WORD_EMBEDDING_DIM ({WORD_EMBEDDING_DIM})\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading prerequisite file: {e}. Please ensure all preprocessing steps are complete.\")\n",
    "    exit()\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Special token {e} not found in loaded vocabularies.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Load Processed Datasets ---\n",
    "try:\n",
    "    train_dataset_processed = load_from_disk(PROCESSED_TRAIN_PATH, keep_in_memory=True)\n",
    "    val_dataset_processed = load_from_disk(PROCESSED_VALIDATION_PATH, keep_in_memory=True)\n",
    "except Exception as e: # More generic catch for Hugging Face load_from_disk issues\n",
    "    print(f\"Error loading processed datasets: {e}\")\n",
    "    print(\"Please ensure your processed data paths are correct and data exists.\")\n",
    "    exit()\n",
    "\n",
    "# Set format for PyTorch\n",
    "columns_to_torch = ['context_ids', 'question_ids', 'context_char_ids', 'question_char_ids',\n",
    "                    'token_answer_start', 'token_answer_end']\n",
    "train_dataset_processed.set_format(type='torch', columns=columns_to_torch)\n",
    "val_dataset_processed.set_format(type='torch', columns=columns_to_torch)\n",
    "\n",
    "\n",
    "# --- DataLoaders ---\n",
    "train_dataloader = DataLoader(train_dataset_processed, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset_processed, batch_size=BATCH_SIZE, shuffle=False) # No shuffle for validation\n",
    "\n",
    "print(f\"DataLoaders created. Train batches: {len(train_dataloader)}, Val batches: {len(val_dataloader)}\")"
   ],
   "id": "86b6250cf6d71263",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Word vocabulary loaded. Size: 103963, PAD_IDX: 0\n",
      "Character vocabulary loaded. Size: 1374, CHAR_PAD_IDX: 0\n",
      "Pretrained word embeddings loaded. Shape: torch.Size([103963, 300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1db22e220c1540758c138fb3e8f593f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created. Train batches: 3650, Val batches: 441\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T10:44:31.616151Z",
     "start_time": "2025-05-07T06:29:55.631663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Model Instantiation (Ensure your BiDAF class definition is available) ---\n",
    "# from your_model_file import BiDAF # Assuming BiDAF class is in another file\n",
    "# For this script, ensure BiDAF class with CharEmbedding is defined above or imported.\n",
    "# Make sure the BiDAF class definition from the previous step is available here.\n",
    "# (The full BiDAF class with CharEmbedding from the previous response should be here)\n",
    "\n",
    "# Re-paste the CharEmbedding, HighwayNetwork, BiDAFAttention, and BiDAF classes here if not imported\n",
    "# For brevity, I'll assume they are defined above this point in your script.\n",
    "# Make sure the BiDAF class from the previous response (with character embeddings) is defined here\n",
    "# For example:\n",
    "# class CharEmbedding(nn.Module): ...\n",
    "# class HighwayNetwork(nn.Module): ...\n",
    "# class BiDAFAttention(nn.Module): ...\n",
    "# class BiDAF(nn.Module): ... (the one that takes char_... params)\n",
    "\n",
    "model = BiDAF(\n",
    "    word_vocab_size=WORD_VOCAB_SIZE,\n",
    "    word_embedding_dim=WORD_EMBEDDING_DIM,\n",
    "    pretrained_word_embeddings=pretrained_word_embeddings,\n",
    "    word_padding_idx=WORD_PADDING_IDX,\n",
    "    char_vocab_size=CHAR_VOCAB_SIZE,\n",
    "    char_embedding_dim=CHAR_EMBEDDING_DIM,\n",
    "    char_cnn_out_channels=CHAR_CNN_OUT_CHANNELS,\n",
    "    char_cnn_kernel_size=CHAR_CNN_KERNEL_SIZE,\n",
    "    char_padding_idx=CHAR_PADDING_IDX,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_highway_layers=NUM_HIGHWAY_LAYERS,\n",
    "    dropout_rate=DROPOUT_RATE\n",
    ").to(device)\n",
    "\n",
    "print(\"BiDAF Model instantiated and moved to device.\")\n",
    "\n",
    "# --- Loss Function and Optimizer ---\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1) # Use -1 if your targets might have it for unanswerable, though SQuAD 1.1 shouldn't\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "\n",
    "# --- Metrics Calculation (Simplified for illustration) ---\n",
    "def compute_metrics(pred_starts, pred_ends, true_starts, true_ends):\n",
    "    # This is a very simplified token-level EM.\n",
    "    # True SQuAD EM/F1 requires text normalization and comparison.\n",
    "    em_sum = 0\n",
    "    f1_sum = 0\n",
    "    num_examples = len(pred_starts)\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        ps, pe = pred_starts[i], pred_ends[i]\n",
    "        ts, te = true_starts[i], true_ends[i]\n",
    "\n",
    "        # Exact Match (token level)\n",
    "        if ps == ts and pe == te:\n",
    "            em_sum += 1\n",
    "\n",
    "        # F1 Score (token level)\n",
    "        pred_tokens = set(range(ps, pe + 1))\n",
    "        true_tokens = set(range(ts, te + 1))\n",
    "\n",
    "        common_tokens = len(pred_tokens.intersection(true_tokens))\n",
    "        if common_tokens == 0:\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            precision = common_tokens / len(pred_tokens)\n",
    "            recall = common_tokens / len(true_tokens)\n",
    "            f1 = (2 * precision * recall) / (precision + recall)\n",
    "        f1_sum += f1\n",
    "\n",
    "    return (em_sum / num_examples) * 100, (f1_sum / num_examples) * 100\n",
    "\n",
    "\n",
    "# --- Training Loop ---\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, clip_norm):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        context_ids = batch['context_ids'].to(device)\n",
    "        question_ids = batch['question_ids'].to(device)\n",
    "        context_char_ids = batch['context_char_ids'].to(device)\n",
    "        question_char_ids = batch['question_char_ids'].to(device)\n",
    "        true_start_idx = batch['token_answer_start'].to(device)\n",
    "        true_end_idx = batch['token_answer_end'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Inside train_epoch, before model call:\n",
    "        if context_ids.max().item() >= WORD_VOCAB_SIZE or context_ids.min().item() < 0:\n",
    "            print(\"Error: context_word_ids out of bounds for word vocab!\")\n",
    "        if context_char_ids.max().item() >= CHAR_VOCAB_SIZE or context_char_ids.min().item() < 0:\n",
    "            print(\"Error: context_char_ids out of bounds for char vocab!\")\n",
    "        # Similar checks for question_ids and question_char_ids\n",
    "\n",
    "        start_logits, end_logits = model(context_word_ids=context_ids,\n",
    "                                         question_word_ids=question_ids,\n",
    "                                         context_char_ids=context_char_ids,\n",
    "                                         question_char_ids=question_char_ids)\n",
    "\n",
    "        if not ((true_start_idx >= 0) & (true_start_idx < start_logits.size(1))).all():\n",
    "            print(\"Error: true_start_idx out of bounds!\")\n",
    "            print(\"Min start_idx:\", true_start_idx.min().item(), \"Max start_idx:\", true_start_idx.max().item())\n",
    "            print(\"Logits shape (num_classes for start):\", start_logits.shape)\n",
    "            # Optionally print the problematic indices/batch\n",
    "            problem_indices_start = ~((true_start_idx >= 0) & (true_start_idx < start_logits.size(1)))\n",
    "            print(\"Problematic true_start_idx:\", true_start_idx[problem_indices_start])\n",
    "            # You might want to raise an error or use pdb here to inspect the batch\n",
    "\n",
    "        if not ((true_end_idx >= 0) & (true_end_idx < end_logits.size(1))).all():\n",
    "            print(\"Error: true_end_idx out of bounds!\")\n",
    "            print(\"Min end_idx:\", true_end_idx.min().item(), \"Max end_idx:\", true_end_idx.max().item())\n",
    "            print(\"Logits shape (num_classes for end):\", end_logits.shape)\n",
    "            problem_indices_end = ~((true_end_idx >= 0) & (true_end_idx < end_logits.size(1)))\n",
    "            print(\"Problematic true_end_idx:\", true_end_idx[problem_indices_end])\n",
    "\n",
    "        # Ensure target indices are valid (not -1 if that was used for unmappable)\n",
    "        # For SQuAD v1.1, start/end should always be valid.\n",
    "        # If there's a possibility of -1 from preprocessing issues:\n",
    "        # valid_indices = (true_start_idx != -1) & (true_end_idx != -1)\n",
    "        # start_logits = start_logits[valid_indices]\n",
    "        # end_logits = end_logits[valid_indices]\n",
    "        # true_start_idx = true_start_idx[valid_indices]\n",
    "        # true_end_idx = true_end_idx[valid_indices]\n",
    "        # if not valid_indices.any(): continue\n",
    "\n",
    "        loss_start = criterion(start_logits, true_start_idx)\n",
    "        loss_end = criterion(end_logits, true_end_idx)\n",
    "        total_loss = loss_start + loss_end\n",
    "\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm) # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += total_loss.item()\n",
    "        progress_bar.set_postfix({'loss': total_loss.item()})\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "\n",
    "# --- Evaluation Loop ---\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_pred_starts, all_pred_ends = [], []\n",
    "    all_true_starts, all_true_ends = [], []\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            context_ids = batch['context_ids'].to(device)\n",
    "            question_ids = batch['question_ids'].to(device)\n",
    "            context_char_ids = batch['context_char_ids'].to(device)\n",
    "            question_char_ids = batch['question_char_ids'].to(device)\n",
    "            true_start_idx = batch['token_answer_start'].to(device)\n",
    "            true_end_idx = batch['token_answer_end'].to(device)\n",
    "\n",
    "            start_logits, end_logits = model(context_word_ids=context_ids,\n",
    "                                             question_word_ids=question_ids,\n",
    "                                             context_char_ids=context_char_ids,\n",
    "                                             question_char_ids=question_char_ids)\n",
    "\n",
    "            loss_start = criterion(start_logits, true_start_idx)\n",
    "            loss_end = criterion(end_logits, true_end_idx)\n",
    "            total_loss = loss_start + loss_end\n",
    "            epoch_loss += total_loss.item()\n",
    "\n",
    "            pred_start_batch = torch.argmax(start_logits, dim=1)\n",
    "            pred_end_batch = torch.argmax(end_logits, dim=1)\n",
    "\n",
    "            all_pred_starts.extend(pred_start_batch.cpu().tolist())\n",
    "            all_pred_ends.extend(pred_end_batch.cpu().tolist())\n",
    "            all_true_starts.extend(true_start_idx.cpu().tolist())\n",
    "            all_true_ends.extend(true_end_idx.cpu().tolist())\n",
    "\n",
    "            progress_bar.set_postfix({'loss': total_loss.item()})\n",
    "\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    em, f1 = compute_metrics(all_pred_starts, all_pred_ends, all_true_starts, all_true_ends)\n",
    "\n",
    "    return avg_loss, em, f1\n",
    "\n",
    "\n",
    "# --- Main Training Orchestration ---\n",
    "best_val_f1 = -1.0\n",
    "model_save_path = \"./bidaf_best_model.pt\"\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, criterion, device, CLIP_GRAD_NORM)\n",
    "    val_loss, val_em, val_f1 = evaluate(model, val_dataloader, criterion, device)\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(val_loss) # Or scheduler.step(val_f1) if using F1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}:\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.4f}\")\n",
    "    print(f\"\\tVal Loss: {val_loss:.4f} | Val EM: {val_em:.2f}% | Val F1: {val_f1:.2f}%\")\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"\\tNew best model saved to {model_save_path} (F1: {best_val_f1:.2f}%)\")\n",
    "\n",
    "print(\"\\nTraining complete.\")\n",
    "print(f\"Best Validation F1: {best_val_f1:.2f}% (Model saved at {model_save_path})\")\n",
    "\n",
    "# To load the best model later:\n",
    "# model.load_state_dict(torch.load(model_save_path))\n",
    "# model.eval()"
   ],
   "id": "2c370f25a2d4a009",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiDAF Model instantiated and moved to device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\ML\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 30/3650 [00:13<24:20,  2.48it/s, loss=8.86] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 175\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 176\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|         | 258/3650 [01:43<21:49,  2.59it/s, loss=7.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 190\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 194\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|        | 680/3650 [04:31<19:44,  2.51it/s, loss=6.97]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 114\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 114\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|       | 872/3650 [05:48<18:27,  2.51it/s, loss=6.05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 160\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 162\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|      | 1166/3650 [07:46<16:30,  2.51it/s, loss=5.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 113\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 114\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|   | 2312/3650 [15:28<08:51,  2.52it/s, loss=5.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 125\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 125\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|   | 2526/3650 [16:52<07:18,  2.57it/s, loss=5.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 135\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 135\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%| | 3243/3650 [21:37<02:39,  2.55it/s, loss=4.92]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 319\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 319\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "\tTrain Loss: 5.6217\n",
      "\tVal Loss: 3.6961 | Val EM: 37.41% | Val F1: 52.81%\n",
      "\tNew best model saved to ./bidaf_best_model.pt (F1: 52.81%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|         | 180/3650 [01:09<22:24,  2.58it/s, loss=2.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 175\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 175\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|        | 734/3650 [04:44<19:04,  2.55it/s, loss=3.4] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 156\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 157\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|       | 793/3650 [05:06<18:27,  2.58it/s, loss=2.82]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 184\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 185\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|       | 941/3650 [06:04<17:27,  2.59it/s, loss=2.19]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 149\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 152\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|      | 1279/3650 [08:15<15:19,  2.58it/s, loss=4.28]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 203\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 205\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|     | 1511/3650 [09:44<13:48,  2.58it/s, loss=3.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 93\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 97\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|    | 2205/3650 [14:12<09:23,  2.56it/s, loss=2.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 296\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 296\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|  | 2735/3650 [17:38<05:54,  2.58it/s, loss=2.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 171\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 172\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "\tTrain Loss: 3.3322\n",
      "\tVal Loss: 3.2098 | Val EM: 43.02% | Val F1: 58.91%\n",
      "\tNew best model saved to ./bidaf_best_model.pt (F1: 58.91%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|        | 570/3650 [03:40<19:52,  2.58it/s, loss=4.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 250\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 250\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|      | 1327/3650 [08:34<15:04,  2.57it/s, loss=2.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 182\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 185\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|    | 2062/3650 [13:19<10:13,  2.59it/s, loss=2.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 154\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 154\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|    | 2143/3650 [13:50<09:44,  2.58it/s, loss=2.32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 174\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 174\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|   | 2335/3650 [15:05<08:29,  2.58it/s, loss=3.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 194\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 213\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|  | 2650/3650 [17:06<06:24,  2.60it/s, loss=3.41]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 174\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 175\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|  | 2833/3650 [18:17<05:17,  2.57it/s, loss=2.69]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 252\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 252\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%| | 3218/3650 [20:46<02:52,  2.50it/s, loss=2.56]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 150\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 151\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "\tTrain Loss: 2.7708\n",
      "\tVal Loss: 3.2406 | Val EM: 43.90% | Val F1: 59.79%\n",
      "\tNew best model saved to ./bidaf_best_model.pt (F1: 59.79%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|         | 144/3650 [00:55<22:37,  2.58it/s, loss=3.19]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 109\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 111\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|        | 572/3650 [03:41<19:47,  2.59it/s, loss=1.67] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 179\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 179\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|       | 977/3650 [06:18<17:20,  2.57it/s, loss=2.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 141\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 147\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|      | 1170/3650 [07:33<16:15,  2.54it/s, loss=1.58] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 167\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 168\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|      | 1382/3650 [08:55<14:47,  2.56it/s, loss=1.65] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 211\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 211\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|     | 1566/3650 [10:06<13:25,  2.59it/s, loss=2.28]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 210\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 215\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|     | 1610/3650 [10:23<13:25,  2.53it/s, loss=3.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 118\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 128\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  71%|   | 2587/3650 [16:41<06:50,  2.59it/s, loss=2.02] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 160\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 165\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "\tTrain Loss: 2.4327\n",
      "\tVal Loss: 3.1978 | Val EM: 44.90% | Val F1: 60.62%\n",
      "\tNew best model saved to ./bidaf_best_model.pt (F1: 60.62%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|        | 496/3650 [03:12<20:36,  2.55it/s, loss=3.36] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 152\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 152\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|        | 502/3650 [03:14<20:51,  2.52it/s, loss=1.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 215\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 220\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|        | 659/3650 [04:15<19:21,  2.57it/s, loss=2.05] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 161\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 161\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|      | 1195/3650 [07:42<15:51,  2.58it/s, loss=2.9]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 213\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 224\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|      | 1437/3650 [09:16<14:21,  2.57it/s, loss=2.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 165\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 167\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%| | 3195/3650 [20:38<02:55,  2.60it/s, loss=2.45] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 166\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 166\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|| 3470/3650 [22:25<01:09,  2.58it/s, loss=2.16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 145\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 145\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|| 3479/3650 [22:28<01:06,  2.58it/s, loss=2.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 160\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 161\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "\tTrain Loss: 2.1899\n",
      "\tVal Loss: 3.3109 | Val EM: 44.30% | Val F1: 60.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|         | 314/3650 [02:01<21:31,  2.58it/s, loss=1.53] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 182\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 182\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|        | 689/3650 [04:26<19:07,  2.58it/s, loss=2.24] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 145\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 149\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|       | 964/3650 [06:13<17:19,  2.58it/s, loss=2.27] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 216\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 219\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|      | 1287/3650 [08:18<15:17,  2.57it/s, loss=1.94] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 152\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 153\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|     | 1739/3650 [11:14<12:10,  2.61it/s, loss=1.23] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 183\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 183\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|   | 2353/3650 [15:13<08:22,  2.58it/s, loss=2.77]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 133\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 133\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|  | 2654/3650 [17:09<06:26,  2.58it/s, loss=2.33] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 246\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 247\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|| 3524/3650 [22:47<00:48,  2.57it/s, loss=2.31] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 194\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 196\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "\tTrain Loss: 1.9948\n",
      "\tVal Loss: 3.3109 | Val EM: 44.26% | Val F1: 60.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|        | 419/3650 [02:42<20:50,  2.58it/s, loss=2.13] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 122\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 128\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|        | 639/3650 [04:07<19:26,  2.58it/s, loss=1.29] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 186\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 188\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|      | 1287/3650 [08:19<15:06,  2.61it/s, loss=2.23] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 181\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 184\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|      | 1503/3650 [09:42<13:57,  2.56it/s, loss=1.66] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 109\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 112\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|  | 2644/3650 [17:08<06:31,  2.57it/s, loss=2.03] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 219\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 221\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|  | 2740/3650 [17:45<05:54,  2.56it/s, loss=1.71] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 167\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 167\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%| | 3175/3650 [20:34<03:03,  2.59it/s, loss=1.85] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 140\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 140\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  94%|| 3417/3650 [22:08<01:29,  2.59it/s, loss=2.73] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 161\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 166\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "\tTrain Loss: 1.8356\n",
      "\tVal Loss: 3.4683 | Val EM: 43.10% | Val F1: 59.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|       | 875/3650 [05:39<17:57,  2.58it/s, loss=1.16] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 106\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 107\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|      | 1323/3650 [08:33<14:57,  2.59it/s, loss=1.29] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 208\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 208\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|      | 1328/3650 [08:35<15:00,  2.58it/s, loss=1.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 172\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 173\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|      | 1470/3650 [09:30<14:04,  2.58it/s, loss=2.25] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 119\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 120\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|     | 1638/3650 [10:35<13:11,  2.54it/s, loss=0.977]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 130\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 133\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|  | 2668/3650 [17:15<06:29,  2.52it/s, loss=1.23] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 244\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 245\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|  | 2764/3650 [17:52<05:42,  2.58it/s, loss=1.75] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 251\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 252\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%| | 2985/3650 [19:18<04:16,  2.59it/s, loss=1.3]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 176\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 176\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "\tTrain Loss: 1.5117\n",
      "\tVal Loss: 3.7345 | Val EM: 43.98% | Val F1: 60.65%\n",
      "\tNew best model saved to ./bidaf_best_model.pt (F1: 60.65%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/3650 [00:01<24:17,  2.50it/s, loss=1.07] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 414\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 421\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|         | 349/3650 [02:15<21:18,  2.58it/s, loss=1.43] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 287\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 291\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|       | 1089/3650 [07:02<16:34,  2.57it/s, loss=0.597]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 162\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 166\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|     | 1557/3650 [10:03<13:23,  2.61it/s, loss=1.71] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 157\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 157\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|     | 1793/3650 [11:35<12:01,  2.57it/s, loss=0.86] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 183\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 184\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|     | 1811/3650 [11:42<11:51,  2.59it/s, loss=1.18] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 189\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 189\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|  | 2653/3650 [17:08<06:26,  2.58it/s, loss=1.76] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 200\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 202\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|  | 2725/3650 [17:36<06:01,  2.56it/s, loss=1.52] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 140\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 142\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "\tTrain Loss: 1.3474\n",
      "\tVal Loss: 3.8669 | Val EM: 43.42% | Val F1: 60.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|       | 1063/3650 [06:53<17:20,  2.49it/s, loss=0.775]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 234\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 235\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|       | 1066/3650 [06:54<17:05,  2.52it/s, loss=0.775]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 257\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 260\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|      | 1165/3650 [07:33<15:54,  2.60it/s, loss=1.15] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 155\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 165\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|      | 1354/3650 [08:46<14:43,  2.60it/s, loss=1.29] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 169\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 201\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|     | 1546/3650 [10:02<14:14,  2.46it/s, loss=1.28] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 149\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 150\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|    | 1908/3650 [12:26<11:17,  2.57it/s, loss=1.75] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 162\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 164\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|   | 2258/3650 [14:42<09:00,  2.58it/s, loss=1.03] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 184\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 186\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%| | 3024/3650 [19:39<04:03,  2.57it/s, loss=1.73] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: true_start_idx out of bounds!\n",
      "Min start_idx: -1 Max start_idx: 204\n",
      "Logits shape (num_classes for start): torch.Size([24, 512])\n",
      "Problematic true_start_idx: tensor([-1], device='cuda:0')\n",
      "Error: true_end_idx out of bounds!\n",
      "Min end_idx: -1 Max end_idx: 204\n",
      "Logits shape (num_classes for end): torch.Size([24, 512])\n",
      "Problematic true_end_idx: tensor([-1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "\tTrain Loss: 1.2436\n",
      "\tVal Loss: 4.0594 | Val EM: 42.86% | Val F1: 59.38%\n",
      "\n",
      "Training complete.\n",
      "Best Validation F1: 60.65% (Model saved at ./bidaf_best_model.pt)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T06:24:23.598485Z",
     "start_time": "2025-05-07T06:24:23.450403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "3a31cfa3ed2df25c",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
